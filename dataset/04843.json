{
  "Title": "[G-11] Do not calculate the length of array multiple of times",
  "Content": "\n**Files:** `L2ContractHelper.sol`, `Compressor.sol`, `BaseZkSyncUpgrade.sol`, `PubdataChunkPublisher.sol`, `Executor.sol`, `DiamondProxy.sol`\n\nWhile calculating the length of an array costs a lot of gas - it's recommended to calculate it once and then, cache the result inside the local variable.\nPlease notice that this is NOT the same issue as bot-report mentions. The bot-report contains instances of calculating array's length in the loop iterator, e.g.: `for (uint i=0; i < array.length; i++)`, while this issue reports that the length of the array is calculated within the loop (line 42).\n\n[File: code/system-contracts/contracts/PubdataChunkPublisher.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/system-contracts/contracts/PubdataChunkPublisher.sol#L36)\n```solidity\n36:         for (uint256 i = 0; i < MAX_NUMBER_OF_BLOBS; i++) {\n37:             uint256 start = BLOB_SIZE_BYTES * i;\n38: \n39:             // We break if the pubdata isn't enough to cover 2 blobs. On L1 it is expected that the hash\n40:             // will be bytes32(0) if a blob isn't going to be used.\n41:             if (start >= _pubdata.length) {\n42:                 break;\n43:             }\n```\n\nIn function `chunkAndPublishPubdata()`, the length of array is calculated on every loop iteration.\n\n[File: code/system-contracts/contracts/Compressor.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/system-contracts/contracts/Compressor.sol#L52)\n```solidity\n52:                 encodedData.length * 4 == _bytecode.length,\n53:                 \"Encoded data length should be 4 times shorter than the original bytecode\"\n54:             );\n55: \n56:             require(\n57:                 dictionary.length / 8 <= encodedData.length / 2,\n58:                 \"Dictionary should have at most the same number of entries as the encoded data\"\n59:             );\n60: \n61:             for (uint256 encodedDataPointer = 0; encodedDataPointer < encodedData.length; encodedDataPointer += 2) {\n62:                 uint256 indexOfEncodedChunk = uint256(encodedData.readUint16(encodedDataPointer)) * 8;\n63:                 require(indexOfEncodedChunk < dictionary.length, \"Encoded chunk index is out of bounds\");\n```\n\n`encodedData.length` is calculated 3 times (lines 52, 57, 61). Calculate it once and cache its value to local variable.\n`dictionary.length` is calculated 2 times (line 57, 63). Calculate it once and cache its value to local variable.\n\n[File: code/contracts/ethereum/contracts/common/libraries/L2ContractHelper.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/contracts/ethereum/contracts/common/libraries/L2ContractHelper.sol#L23)\n```solidity\n23:         require(_bytecode.length % 32 == 0, \"pq\");\n24: \n25:         uint256 bytecodeLenInWords = _bytecode.length / 32;\n```\n`_bytecode.length` is calculated twice, it would be more efficient to calculate it once and cache the result before line 23.\n\n[File: code/contracts/ethereum/contracts/upgrades/BaseZkSyncUpgrade.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/contracts/ethereum/contracts/upgrades/BaseZkSyncUpgrade.sol#L223)\n```solidity\n223:         require(_factoryDeps.length == _expectedHashes.length, \"Wrong number of factory deps\");\n224:         require(_factoryDeps.length <= MAX_NEW_FACTORY_DEPS, \"Factory deps can be at most 32\");\n225: \n226:         for (uint256 i = 0; i < _factoryDeps.length; ++i) {\n```\n`_factoryDeps.length` is calculated 3 times (lines 223, 224, 226). Calculate it once and cache the result into local variable before line 223.\n\n[File: code/contracts/ethereum/contracts/state-transition/chain-deps/DiamondProxy.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/contracts/ethereum/contracts/state-transition/chain-deps/DiamondProxy.sol#L25)\n```solidity\n25:         require(msg.data.length >= 4 || msg.data.length == 0, \"Ut\");\n```\n\n`msg.data.length` is calculated twice. Calculate it once and cache the result into local variable.\n\n[File: code/contracts/ethereum/contracts/state-transition/chain-deps/facets/Executor.sol](https://github.com/code-423n4/2024-03-zksync/blob/main/code/contracts/ethereum/contracts/state-transition/chain-deps/facets/Executor.sol#L631)\n```solidity\n631:         require(_pubdataCommitments.length > 0, \"pl\");\n632:         require(_pubdataCommitments.length <= PUBDATA_COMMITMENT_SIZE * MAX_NUMBER_OF_BLOBS, \"bd\");\n633:         require(_pubdataCommitments.length % PUBDATA_COMMITMENT_SIZE == 0, \"bs\");\n634:         blobCommitments = new bytes32[](MAX_NUMBER_OF_BLOBS);\n635: \n636:         for (uint256 i = 0; i < _pubdataCommitments.length; i += PUBDATA_COMMITMENT_SIZE) {\n```\n\n`_pubdataCommitments.length` is calculated 4 times (lines 631, 632, 633m 636). Calculate it once and cache the result into local variable.\n\n",
  "Impact": "GAS",
  "Source": "https://code4rena.com/reports/2024-03-zksync",
  "Code": [
    {
      "filename": "code/system-contracts/contracts/PubdataChunkPublisher.sol",
      "content": "// SPDX-License-Identifier: MIT\npragma solidity 0.8.20;\n\nimport {IPubdataChunkPublisher} from \"./interfaces/IPubdataChunkPublisher.sol\";\nimport {ISystemContract} from \"./interfaces/ISystemContract.sol\";\nimport {L1_MESSENGER_CONTRACT, BLOB_SIZE_BYTES, MAX_NUMBER_OF_BLOBS} from \"./Constants.sol\";\nimport {EfficientCall} from \"./libraries/EfficientCall.sol\";\nimport {SystemContractHelper} from \"./libraries/SystemContractHelper.sol\";\nimport {SystemLogKey} from \"./Constants.sol\";\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Smart contract for chunking pubdata into the appropriate size for EIP-4844 blobs.\n */\ncontract PubdataChunkPublisher is IPubdataChunkPublisher, ISystemContract {\n    /// @notice Chunks pubdata into pieces that can fit into blobs.\n    /// @param _pubdata The total l2 to l1 pubdata that will be sent via L1 blobs.\n    /// @dev Note: This is an early implementation, in the future we plan to support up to 16 blobs per l1 batch.\n    /// @dev We always publish 2 system logs even if our pubdata fits into a single blob. This makes processing logs on L1 easier.\n    function chunkAndPublishPubdata(bytes calldata _pubdata) external onlyCallFrom(address(L1_MESSENGER_CONTRACT)) {\n        require(_pubdata.length <= BLOB_SIZE_BYTES * MAX_NUMBER_OF_BLOBS, \"pubdata should fit in 2 blobs\");\n\n        bytes32[] memory blobHashes = new bytes32[](MAX_NUMBER_OF_BLOBS);\n\n        // We allocate to the full size of MAX_NUMBER_OF_BLOBS * BLOB_SIZE_BYTES because we need to pad\n        // the data on the right with 0s if it doesn't take up the full blob\n        bytes memory totalBlobs = new bytes(BLOB_SIZE_BYTES * MAX_NUMBER_OF_BLOBS);\n\n        assembly {\n            // The pointer to the allocated memory above. We skip 32 bytes to avoid overwriting the length.\n            let ptr := add(totalBlobs, 0x20)\n            calldatacopy(ptr, _pubdata.offset, _pubdata.length)\n        }\n\n        for (uint256 i = 0; i < MAX_NUMBER_OF_BLOBS; i++) {\n            uint256 start = BLOB_SIZE_BYTES * i;\n\n            // We break if the pubdata isn't enough to cover 2 blobs. On L1 it is expected that the hash\n            // will be bytes32(0) if a blob isn't going to be used.\n            if (start >= _pubdata.length) {\n                break;\n            }\n\n            bytes32 blobHash;\n            assembly {\n                // The pointer to the allocated memory above skipping the length.\n                let ptr := add(totalBlobs, 0x20)\n                blobHash := keccak256(add(ptr, start), BLOB_SIZE_BYTES)\n            }\n\n            blobHashes[i] = blobHash;\n        }\n\n        SystemContractHelper.toL1(true, bytes32(uint256(SystemLogKey.BLOB_ONE_HASH_KEY)), blobHashes[0]);\n        SystemContractHelper.toL1(true, bytes32(uint256(SystemLogKey.BLOB_TWO_HASH_KEY)), blobHashes[1]);\n    }\n}"
    },
    {
      "filename": "code/system-contracts/contracts/Compressor.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity 0.8.20;\n\nimport {ICompressor, OPERATION_BITMASK, LENGTH_BITS_OFFSET, MAX_ENUMERATION_INDEX_SIZE} from \"./interfaces/ICompressor.sol\";\nimport {ISystemContract} from \"./interfaces/ISystemContract.sol\";\nimport {Utils} from \"./libraries/Utils.sol\";\nimport {UnsafeBytesCalldata} from \"./libraries/UnsafeBytesCalldata.sol\";\nimport {EfficientCall} from \"./libraries/EfficientCall.sol\";\nimport {L1_MESSENGER_CONTRACT, INITIAL_WRITE_STARTING_POSITION, COMPRESSED_INITIAL_WRITE_SIZE, STATE_DIFF_ENTRY_SIZE, STATE_DIFF_ENUM_INDEX_OFFSET, STATE_DIFF_FINAL_VALUE_OFFSET, STATE_DIFF_DERIVED_KEY_OFFSET, DERIVED_KEY_LENGTH, VALUE_LENGTH, ENUM_INDEX_LENGTH, KNOWN_CODE_STORAGE_CONTRACT} from \"./Constants.sol\";\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Contract with code pertaining to compression for zkEVM; at the moment this is used for bytecode compression\n * and state diff compression validation.\n * @dev Every deployed bytecode/published state diffs in zkEVM should be publicly restorable from the L1 data availability.\n * For this reason, the user may request the sequencer to publish the original bytecode and mark it as known.\n * Or the user may compress the bytecode and publish it instead (fewer data onchain!). At the end of every L1 Batch\n * we publish pubdata, part of which contains the state diffs that occurred within the batch.\n */\ncontract Compressor is ICompressor, ISystemContract {\n    using UnsafeBytesCalldata for bytes;\n\n    /// @notice Verify the compressed bytecode and publish it on the L1.\n    /// @param _bytecode The original bytecode to be verified against.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    /// @return bytecodeHash The hash of the original bytecode.\n    /// @dev The dictionary is a sequence of 8-byte chunks, each of them has the associated index.\n    /// @dev The encoded data is a sequence of 2-byte chunks, each of them is an index of the dictionary.\n    /// @dev The compression algorithm works as follows:\n    ///     1. The original bytecode is split into 8-byte chunks.\n    ///     Since the bytecode size is always a multiple of 32, this is always possible.\n    ///     2. For each 8-byte chunk in the original bytecode:\n    ///         * If the chunk is not already in the dictionary, it is added to the dictionary array.\n    ///         * If the dictionary becomes overcrowded (2^16 + 1 elements), the compression process will fail.\n    ///         * The 2-byte index of the chunk in the dictionary is added to the encoded data.\n    /// @dev Currently, the method may be called only from the bootloader because the server is not ready to publish bytecodes\n    /// in internal transactions. However, in the future, we will allow everyone to publish compressed bytecodes.\n    /// @dev Read more about the compression: https://github.com/matter-labs/zksync-era/blob/main/docs/guides/advanced/compression.md\n    function publishCompressedBytecode(\n        bytes calldata _bytecode,\n        bytes calldata _rawCompressedData\n    ) external payable onlyCallFromBootloader returns (bytes32 bytecodeHash) {\n        unchecked {\n            (bytes calldata dictionary, bytes calldata encodedData) = _decodeRawBytecode(_rawCompressedData);\n\n            require(\n                encodedData.length * 4 == _bytecode.length,\n                \"Encoded data length should be 4 times shorter than the original bytecode\"\n            );\n\n            require(\n                dictionary.length / 8 <= encodedData.length / 2,\n                \"Dictionary should have at most the same number of entries as the encoded data\"\n            );\n\n            for (uint256 encodedDataPointer = 0; encodedDataPointer < encodedData.length; encodedDataPointer += 2) {\n                uint256 indexOfEncodedChunk = uint256(encodedData.readUint16(encodedDataPointer)) * 8;\n                require(indexOfEncodedChunk < dictionary.length, \"Encoded chunk index is out of bounds\");\n\n                uint64 encodedChunk = dictionary.readUint64(indexOfEncodedChunk);\n                uint64 realChunk = _bytecode.readUint64(encodedDataPointer * 4);\n\n                require(encodedChunk == realChunk, \"Encoded chunk does not match the original bytecode\");\n            }\n        }\n\n        bytecodeHash = Utils.hashL2Bytecode(_bytecode);\n        L1_MESSENGER_CONTRACT.sendToL1(_rawCompressedData);\n        KNOWN_CODE_STORAGE_CONTRACT.markBytecodeAsPublished(bytecodeHash);\n    }\n\n    /// @notice Verifies that the compression of state diffs has been done correctly for the {_stateDiffs} param.\n    /// @param _numberOfStateDiffs The number of state diffs being checked.\n    /// @param _enumerationIndexSize Number of bytes used to represent an enumeration index for repeated writes.\n    /// @param _stateDiffs Encoded full state diff structs. See the first dev comment below for encoding.\n    /// @param _compressedStateDiffs The compressed state diffs\n    /// @dev We don't verify that the size of {_stateDiffs} is equivalent to {_numberOfStateDiffs} * STATE_DIFF_ENTRY_SIZE since that check is\n    ///      done within the L1Messenger calling contract.\n    /// @return stateDiffHash Hash of the encoded (uncompressed) state diffs to be committed to via system log.\n    /// @dev This check assumes that the ordering of state diffs are sorted by (address, key) for the encoded state diffs and\n    ///      then the compressed are sorted the same but with all the initial writes coming before the repeated writes.\n    /// @dev state diff:   [20bytes address][32bytes key][32bytes derived key][8bytes enum index][32bytes initial value][32bytes final value]\n    /// @dev The compression format:\n    ///     - 2 bytes: number of initial writes\n    ///     - N bytes initial writes\n    ///         - 32 bytes derived key\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    ///     - M bytes repeated writes\n    ///         - {_enumerationIndexSize} bytes for enumeration index\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    function verifyCompressedStateDiffs(\n        uint256 _numberOfStateDiffs,\n        uint256 _enumerationIndexSize,\n        bytes calldata _stateDiffs,\n        bytes calldata _compressedStateDiffs\n    ) external payable onlyCallFrom(address(L1_MESSENGER_CONTRACT)) returns (bytes32 stateDiffHash) {\n        // We do not enforce the operator to use the optimal, i.e. the minimally possible _enumerationIndexSize.\n        // We do enforce however, that the _enumerationIndexSize is not larger than 8 bytes long, which is the\n        // maximal ever possible size for enumeration index.\n        require(_enumerationIndexSize <= MAX_ENUMERATION_INDEX_SIZE, \"enumeration index size is too large\");\n\n        uint256 numberOfInitialWrites = uint256(_compressedStateDiffs.readUint16(0));\n\n        uint256 stateDiffPtr = 2;\n        uint256 numInitialWritesProcessed = 0;\n\n        // Process initial writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex != 0) {\n                // It is a repeated write, so we skip it.\n                continue;\n            }\n\n            numInitialWritesProcessed++;\n\n            bytes32 derivedKey = stateDiff.readBytes32(52);\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            require(derivedKey == _compressedStateDiffs.readBytes32(stateDiffPtr), \"iw: initial key mismatch\");\n            stateDiffPtr += 32;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr++;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(numInitialWritesProcessed == numberOfInitialWrites, \"Incorrect number of initial storage diffs\");\n\n        // Process repeated writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex == 0) {\n                continue;\n            }\n\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            uint256 compressedEnumIndex = _sliceToUint256(\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + _enumerationIndexSize]\n            );\n            require(enumIndex == compressedEnumIndex, \"rw: enum key mismatch\");\n            stateDiffPtr += _enumerationIndexSize;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr += 1;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(stateDiffPtr == _compressedStateDiffs.length, \"Extra data in _compressedStateDiffs\");\n\n        stateDiffHash = EfficientCall.keccak(_stateDiffs);\n    }\n\n    /// @notice Decode the raw compressed data into the dictionary and the encoded data.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the bytes length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    function _decodeRawBytecode(\n        bytes calldata _rawCompressedData\n    ) internal pure returns (bytes calldata dictionary, bytes calldata encodedData) {\n        unchecked {\n            // The dictionary length can't be more than 2^16, so it fits into 2 bytes.\n            uint256 dictionaryLen = uint256(_rawCompressedData.readUint16(0));\n            dictionary = _rawCompressedData[2:2 + dictionaryLen * 8];\n            encodedData = _rawCompressedData[2 + dictionaryLen * 8:];\n        }\n    }\n\n    /// @notice Verify value compression was done correct given initial value, final value, operation, and compressed value\n    /// @param _initialValue Previous value of key/enumeration index.\n    /// @param _finalValue Updated value of key/enumeration index.\n    /// @param _operation The operation that was performed on value.\n    /// @param _compressedValue The slice of calldata with compressed value either representing the final\n    /// value or difference between initial and final value. It should be of arbitrary length less than or equal to 32 bytes.\n    /// @dev It is the responsibility of the caller of this function to ensure that the `_compressedValue` has length no longer than 32 bytes.\n    /// @dev Operation id mapping:\n    /// 0 -> Nothing (32 bytes)\n    /// 1 -> Add\n    /// 2 -> Subtract\n    /// 3 -> Transform (< 32 bytes)\n    function _verifyValueCompression(\n        uint256 _initialValue,\n        uint256 _finalValue,\n        uint256 _operation,\n        bytes calldata _compressedValue\n    ) internal pure {\n        uint256 convertedValue = _sliceToUint256(_compressedValue);\n\n        unchecked {\n            if (_operation == 0 || _operation == 3) {\n                require(convertedValue == _finalValue, \"transform or no compression: compressed and final mismatch\");\n            } else if (_operation == 1) {\n                require(\n                    _initialValue + convertedValue == _finalValue,\n                    \"add: initial plus converted not equal to final\"\n                );\n            } else if (_operation == 2) {\n                require(\n                    _initialValue - convertedValue == _finalValue,\n                    \"sub: initial minus converted not equal to final\"\n                );\n            } else {\n                revert(\"unsupported operation\");\n            }\n        }\n    }\n\n    /// @notice Converts a calldata slice into uint256. It is the responsibility of the caller to ensure that\n    /// the _calldataSlice has length no longer than 32 bytes\n    /// @param _calldataSlice The calldata slice to convert to uint256\n    /// @return number The uint256 representation of the calldata slice\n    function _sliceToUint256(bytes calldata _calldataSlice) internal pure returns (uint256 number) {\n        number = uint256(bytes32(_calldataSlice));\n        number >>= (256 - (_calldataSlice.length * 8));\n    }\n}"
    },
    {
      "filename": "code/contracts/ethereum/contracts/common/libraries/L2ContractHelper.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity 0.8.20;\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Helper library for working with L2 contracts on L1.\n */\nlibrary L2ContractHelper {\n    /// @dev The prefix used to create CREATE2 addresses.\n    bytes32 private constant CREATE2_PREFIX = keccak256(\"zksyncCreate2\");\n\n    /// @notice Validate the bytecode format and calculate its hash.\n    /// @param _bytecode The bytecode to hash.\n    /// @return hashedBytecode The 32-byte hash of the bytecode.\n    /// Note: The function reverts the execution if the bytecode has non expected format:\n    /// - Bytecode bytes length is not a multiple of 32\n    /// - Bytecode bytes length is not less than 2^21 bytes (2^16 words)\n    /// - Bytecode words length is not odd\n    function hashL2Bytecode(bytes memory _bytecode) internal pure returns (bytes32 hashedBytecode) {\n        // Note that the length of the bytecode must be provided in 32-byte words.\n        require(_bytecode.length % 32 == 0, \"pq\");\n\n        uint256 bytecodeLenInWords = _bytecode.length / 32;\n        require(bytecodeLenInWords < 2 ** 16, \"pp\"); // bytecode length must be less than 2^16 words\n        require(bytecodeLenInWords % 2 == 1, \"ps\"); // bytecode length in words must be odd\n        hashedBytecode = sha256(_bytecode) & 0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF;\n        // Setting the version of the hash\n        hashedBytecode = (hashedBytecode | bytes32(uint256(1 << 248)));\n        // Setting the length\n        hashedBytecode = hashedBytecode | bytes32(bytecodeLenInWords << 224);\n    }\n\n    /// @notice Validates the format of the given bytecode hash.\n    /// @dev Due to the specification of the L2 bytecode hash, not every 32 bytes could be a legit bytecode hash.\n    /// @dev The function reverts on invalid bytecode hash formam.\n    /// @param _bytecodeHash The hash of the bytecode to validate.\n    function validateBytecodeHash(bytes32 _bytecodeHash) internal pure {\n        uint8 version = uint8(_bytecodeHash[0]);\n        require(version == 1 && _bytecodeHash[1] == bytes1(0), \"zf\"); // Incorrectly formatted bytecodeHash\n\n        require(bytecodeLen(_bytecodeHash) % 2 == 1, \"uy\"); // Code length in words must be odd\n    }\n\n    /// @notice Returns the length of the bytecode associated with the given hash.\n    /// @param _bytecodeHash The hash of the bytecode.\n    /// @return codeLengthInWords The length of the bytecode in words.\n    function bytecodeLen(bytes32 _bytecodeHash) internal pure returns (uint256 codeLengthInWords) {\n        codeLengthInWords = uint256(uint8(_bytecodeHash[2])) * 256 + uint256(uint8(_bytecodeHash[3]));\n    }\n\n    /// @notice Computes the create2 address for a Layer 2 contract.\n    /// @param _sender The address of the sender.\n    /// @param _salt The salt value to use in the create2 address computation.\n    /// @param _bytecodeHash The contract bytecode hash.\n    /// @param _constructorInputHash The hash of the constructor input data.\n    /// @return The create2 address of the contract.\n    /// NOTE: L2 create2 derivation is different from L1 derivation!\n    function computeCreate2Address(\n        address _sender,\n        bytes32 _salt,\n        bytes32 _bytecodeHash,\n        bytes32 _constructorInputHash\n    ) internal pure returns (address) {\n        bytes32 senderBytes = bytes32(uint256(uint160(_sender)));\n        bytes32 data = keccak256(\n            bytes.concat(CREATE2_PREFIX, senderBytes, _salt, _bytecodeHash, _constructorInputHash)\n        );\n\n        return address(uint160(uint256(data)));\n    }\n}"
    },
    {
      "filename": "code/contracts/ethereum/contracts/upgrades/BaseZkSyncUpgrade.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity 0.8.20;\n\nimport {ZkSyncStateTransitionBase} from \"../state-transition/chain-deps/facets/ZkSyncStateTransitionBase.sol\";\nimport {IMailbox} from \"../state-transition/chain-interfaces/IMailbox.sol\";\nimport {VerifierParams} from \"../state-transition/chain-interfaces/IVerifier.sol\";\nimport {IVerifier} from \"../state-transition/chain-interfaces/IVerifier.sol\";\nimport {L2ContractHelper} from \"../common/libraries/L2ContractHelper.sol\";\nimport {TransactionValidator} from \"../state-transition/libraries/TransactionValidator.sol\";\nimport {MAX_NEW_FACTORY_DEPS, SYSTEM_UPGRADE_L2_TX_TYPE, MAX_ALLOWED_PROTOCOL_VERSION_DELTA} from \"../common/Config.sol\";\nimport {L2CanonicalTransaction} from \"../common/Messaging.sol\";\n\n/// @notice The struct that represents the upgrade proposal.\n/// @param l2ProtocolUpgradeTx The system upgrade transaction.\n/// @param factoryDeps The list of factory deps for the l2ProtocolUpgradeTx.\n/// @param bootloaderHash The hash of the new bootloader bytecode. If zero, it will not be updated.\n/// @param defaultAccountHash The hash of the new default account bytecode. If zero, it will not be updated.\n/// @param verifier The address of the new verifier. If zero, the verifier will not be updated.\n/// @param verifierParams The new verifier params. If all of its fields are 0, the params will not be updated.\n/// @param l1ContractsUpgradeCalldata Custom calldata for L1 contracts upgrade, it may be interpreted differently\n/// in each upgrade. Usually empty.\n/// @param postUpgradeCalldata Custom calldata for post upgrade hook, it may be interpreted differently in each\n/// upgrade. Usually empty.\n/// @param upgradeTimestamp The timestamp after which the upgrade can be executed.\n/// @param newProtocolVersion The new version number for the protocol after this upgrade. Should be greater than\n/// the previous protocol version.\nstruct ProposedUpgrade {\n    L2CanonicalTransaction l2ProtocolUpgradeTx;\n    bytes[] factoryDeps;\n    bytes32 bootloaderHash;\n    bytes32 defaultAccountHash;\n    address verifier;\n    VerifierParams verifierParams;\n    bytes l1ContractsUpgradeCalldata;\n    bytes postUpgradeCalldata;\n    uint256 upgradeTimestamp;\n    uint256 newProtocolVersion;\n}\n\n/// @author Matter Labs\n/// @custom:security-contact security@matterlabs.dev\n/// @notice Interface to which all the upgrade implementations should adhere\nabstract contract BaseZkSyncUpgrade is ZkSyncStateTransitionBase {\n    /// @notice Changes the protocol version\n    event NewProtocolVersion(uint256 indexed previousProtocolVersion, uint256 indexed newProtocolVersion);\n\n    /// @notice Сhanges to the bytecode that is used in L2 as a bootloader (start program)\n    event NewL2BootloaderBytecodeHash(bytes32 indexed previousBytecodeHash, bytes32 indexed newBytecodeHash);\n\n    /// @notice Сhanges to the bytecode that is used in L2 as a default account\n    event NewL2DefaultAccountBytecodeHash(bytes32 indexed previousBytecodeHash, bytes32 indexed newBytecodeHash);\n\n    /// @notice Verifier address changed\n    event NewVerifier(address indexed oldVerifier, address indexed newVerifier);\n\n    /// @notice Verifier parameters changed\n    event NewVerifierParams(VerifierParams oldVerifierParams, VerifierParams newVerifierParams);\n\n    /// @notice Notifies about complete upgrade\n    event UpgradeComplete(uint256 indexed newProtocolVersion, bytes32 indexed l2UpgradeTxHash, ProposedUpgrade upgrade);\n\n    /// @notice The main function that will be provided by the upgrade proxy\n    /// @dev This is a virtual function and should be overridden by custom upgrade implementations.\n    /// @param _proposedUpgrade The upgrade to be executed.\n    /// @return txHash The hash of the L2 system contract upgrade transaction.\n    function upgrade(ProposedUpgrade calldata _proposedUpgrade) public virtual returns (bytes32 txHash) {\n        // Note that due to commitment delay, the timestamp of the L2 upgrade batch may be earlier than the timestamp\n        // of the L1 block at which the upgrade occurred. This means that using timestamp as a signifier of \"upgraded\"\n        // on the L2 side would be inaccurate. The effects of this \"back-dating\" of L2 upgrade batches will be reduced\n        // as the permitted delay window is reduced in the future.\n        require(block.timestamp >= _proposedUpgrade.upgradeTimestamp, \"Upgrade is not ready yet\");\n\n        _setNewProtocolVersion(_proposedUpgrade.newProtocolVersion);\n        _upgradeL1Contract(_proposedUpgrade.l1ContractsUpgradeCalldata);\n        _upgradeVerifier(_proposedUpgrade.verifier, _proposedUpgrade.verifierParams);\n        _setBaseSystemContracts(_proposedUpgrade.bootloaderHash, _proposedUpgrade.defaultAccountHash);\n\n        txHash = _setL2SystemContractUpgrade(\n            _proposedUpgrade.l2ProtocolUpgradeTx,\n            _proposedUpgrade.factoryDeps,\n            _proposedUpgrade.newProtocolVersion\n        );\n\n        _postUpgrade(_proposedUpgrade.postUpgradeCalldata);\n\n        emit UpgradeComplete(_proposedUpgrade.newProtocolVersion, txHash, _proposedUpgrade);\n    }\n\n    /// @notice Change default account bytecode hash, that is used on L2\n    /// @param _l2DefaultAccountBytecodeHash The hash of default account L2 bytecode\n    function _setL2DefaultAccountBytecodeHash(bytes32 _l2DefaultAccountBytecodeHash) private {\n        if (_l2DefaultAccountBytecodeHash == bytes32(0)) {\n            return;\n        }\n\n        L2ContractHelper.validateBytecodeHash(_l2DefaultAccountBytecodeHash);\n\n        // Save previous value into the stack to put it into the event later\n        bytes32 previousDefaultAccountBytecodeHash = s.l2DefaultAccountBytecodeHash;\n\n        // Change the default account bytecode hash\n        s.l2DefaultAccountBytecodeHash = _l2DefaultAccountBytecodeHash;\n        emit NewL2DefaultAccountBytecodeHash(previousDefaultAccountBytecodeHash, _l2DefaultAccountBytecodeHash);\n    }\n\n    /// @notice Change bootloader bytecode hash, that is used on L2\n    /// @param _l2BootloaderBytecodeHash The hash of bootloader L2 bytecode\n    function _setL2BootloaderBytecodeHash(bytes32 _l2BootloaderBytecodeHash) private {\n        if (_l2BootloaderBytecodeHash == bytes32(0)) {\n            return;\n        }\n\n        L2ContractHelper.validateBytecodeHash(_l2BootloaderBytecodeHash);\n\n        // Save previous value into the stack to put it into the event later\n        bytes32 previousBootloaderBytecodeHash = s.l2BootloaderBytecodeHash;\n\n        // Change the bootloader bytecode hash\n        s.l2BootloaderBytecodeHash = _l2BootloaderBytecodeHash;\n        emit NewL2BootloaderBytecodeHash(previousBootloaderBytecodeHash, _l2BootloaderBytecodeHash);\n    }\n\n    /// @notice Change the address of the verifier smart contract\n    /// @param _newVerifier Verifier smart contract address\n    function _setVerifier(IVerifier _newVerifier) private {\n        // An upgrade to the verifier must be done carefully to ensure there aren't batches in the committed state\n        // during the transition. If verifier is upgraded, it will immediately be used to prove all committed batches.\n        // Batches committed expecting the old verifier will fail. Ensure all commited batches are finalized before the\n        // verifier is upgraded.\n        if (_newVerifier == IVerifier(address(0))) {\n            return;\n        }\n\n        IVerifier oldVerifier = s.verifier;\n        s.verifier = _newVerifier;\n        emit NewVerifier(address(oldVerifier), address(_newVerifier));\n    }\n\n    /// @notice Change the verifier parameters\n    /// @param _newVerifierParams New parameters for the verifier\n    function _setVerifierParams(VerifierParams calldata _newVerifierParams) private {\n        // An upgrade to the verifier params must be done carefully to ensure there aren't batches in the committed state\n        // during the transition. If verifier is upgraded, it will immediately be used to prove all committed batches.\n        // Batches committed expecting the old verifier params will fail. Ensure all commited batches are finalized before the\n        // verifier is upgraded.\n        if (\n            _newVerifierParams.recursionNodeLevelVkHash == bytes32(0) &&\n            _newVerifierParams.recursionLeafLevelVkHash == bytes32(0) &&\n            _newVerifierParams.recursionCircuitsSetVksHash == bytes32(0)\n        ) {\n            return;\n        }\n\n        VerifierParams memory oldVerifierParams = s.verifierParams;\n        s.verifierParams = _newVerifierParams;\n        emit NewVerifierParams(oldVerifierParams, _newVerifierParams);\n    }\n\n    /// @notice Updates the verifier and the verifier params\n    /// @param _newVerifier The address of the new verifier. If 0, the verifier will not be updated.\n    /// @param _verifierParams The new verifier params. If all of the fields are 0, the params will not be updated.\n    function _upgradeVerifier(address _newVerifier, VerifierParams calldata _verifierParams) internal {\n        _setVerifier(IVerifier(_newVerifier));\n        _setVerifierParams(_verifierParams);\n    }\n\n    /// @notice Updates the bootloader hash and the hash of the default account\n    /// @param _bootloaderHash The hash of the new bootloader bytecode. If zero, it will not be updated.\n    /// @param _defaultAccountHash The hash of the new default account bytecode. If zero, it will not be updated.\n    function _setBaseSystemContracts(bytes32 _bootloaderHash, bytes32 _defaultAccountHash) internal {\n        _setL2BootloaderBytecodeHash(_bootloaderHash);\n        _setL2DefaultAccountBytecodeHash(_defaultAccountHash);\n    }\n\n    /// @notice Sets the hash of the L2 system contract upgrade transaction for the next batch to be committed\n    /// @dev If the transaction is noop (i.e. its type is 0) it does nothing and returns 0.\n    /// @param _l2ProtocolUpgradeTx The L2 system contract upgrade transaction.\n    /// @return System contracts upgrade transaction hash. Zero if no upgrade transaction is set.\n    function _setL2SystemContractUpgrade(\n        L2CanonicalTransaction calldata _l2ProtocolUpgradeTx,\n        bytes[] calldata _factoryDeps,\n        uint256 _newProtocolVersion\n    ) internal returns (bytes32) {\n        // If the type is 0, it is considered as noop and so will not be required to be executed.\n        if (_l2ProtocolUpgradeTx.txType == 0) {\n            return bytes32(0);\n        }\n\n        require(_l2ProtocolUpgradeTx.txType == SYSTEM_UPGRADE_L2_TX_TYPE, \"L2 system upgrade tx type is wrong\");\n\n        bytes memory encodedTransaction = abi.encode(_l2ProtocolUpgradeTx);\n\n        TransactionValidator.validateL1ToL2Transaction(\n            _l2ProtocolUpgradeTx,\n            encodedTransaction,\n            s.priorityTxMaxGasLimit,\n            s.feeParams.priorityTxMaxPubdata\n        );\n\n        TransactionValidator.validateUpgradeTransaction(_l2ProtocolUpgradeTx);\n\n        // We want the hashes of l2 system upgrade transactions to be unique.\n        // This is why we require that the `nonce` field is unique to each upgrade.\n        require(\n            _l2ProtocolUpgradeTx.nonce == _newProtocolVersion,\n            \"The new protocol version should be included in the L2 system upgrade tx\"\n        );\n\n        _verifyFactoryDeps(_factoryDeps, _l2ProtocolUpgradeTx.factoryDeps);\n\n        bytes32 l2ProtocolUpgradeTxHash = keccak256(encodedTransaction);\n\n        s.l2SystemContractsUpgradeTxHash = l2ProtocolUpgradeTxHash;\n\n        return l2ProtocolUpgradeTxHash;\n    }\n\n    /// @notice Verifies that the factory deps correspond to the proper hashes\n    /// @param _factoryDeps The list of factory deps\n    /// @param _expectedHashes The list of expected bytecode hashes\n    function _verifyFactoryDeps(bytes[] calldata _factoryDeps, uint256[] calldata _expectedHashes) private pure {\n        require(_factoryDeps.length == _expectedHashes.length, \"Wrong number of factory deps\");\n        require(_factoryDeps.length <= MAX_NEW_FACTORY_DEPS, \"Factory deps can be at most 32\");\n\n        for (uint256 i = 0; i < _factoryDeps.length; ++i) {\n            require(\n                L2ContractHelper.hashL2Bytecode(_factoryDeps[i]) == bytes32(_expectedHashes[i]),\n                \"Wrong factory dep hash\"\n            );\n        }\n    }\n\n    /// @notice Changes the protocol version\n    /// @param _newProtocolVersion The new protocol version\n    function _"
    }
  ]
}