{
  "Title": "[03] The new `require(dictionary.length / 8 <= encodedData.length / 2)` check allows malicious operators to always pass in malformed data to the bootloader to ensure that all users gas gets burnt without executing the tx.",
  "Content": "\n### Proof of Concept\n\nTake a look at https://github.com/code-423n4/2024-03-zksync/blob/4f0ba34f34a864c354c7e8c47643ed8f4a250e13/code/system-contracts/contracts/Compressor.sol#L44-L70\n\n```solidity\n    function publishCompressedBytecode(\n        bytes calldata _bytecode,\n        bytes calldata _rawCompressedData\n    ) external payable onlyCallFromBootloader returns (bytes32 bytecodeHash) {\n        unchecked {\n            (bytes calldata dictionary, bytes calldata encodedData) = _decodeRawBytecode(_rawCompressedData);\n\n\n            require(\n                encodedData.length * 4 == _bytecode.length,\n                \"Encoded data length should be 4 times shorter than the original bytecode\"\n            );\n\n\n            require(\n                dictionary.length / 8 <= encodedData.length / 2,\n                \"Dictionary should have at most the same number of entries as the encoded data\"\n            );\n\n\n            for (uint256 encodedDataPointer = 0; encodedDataPointer < encodedData.length; encodedDataPointer += 2) {\n                uint256 indexOfEncodedChunk = uint256(encodedData.readUint16(encodedDataPointer)) * 8;\n                require(indexOfEncodedChunk < dictionary.length, \"Encoded chunk index is out of bounds\");\n\n\n                uint64 encodedChunk = dictionary.readUint64(indexOfEncodedChunk);\n                uint64 realChunk = _bytecode.readUint64(encodedDataPointer * 4);\n\n\n                require(encodedChunk == realChunk, \"Encoded chunk does not match the original bytecode\");\n            }\n        }\n```\n\nThe `publishCompressedBytecode()` function has been updated, and here is the new implementation https://github.com/code-423n4/2024-03-zksync/blob/4f0ba34f34a864c354c7e8c47643ed8f4a250e13/code/system-contracts/contracts/Compressor.sol#L44-L70, in comparison to the previous implementation, it no longer enforces multiple checks, i.e the `dictionary.length % 8 = 0` and the check where the dictionary's length `< 2** 16` this is done so that protocol can correctly enforce more that the reason why a call to this function fails would be due to gas from the bootloader, but there is a new check that faults this logic , i.e `require(dictionary.length / 8 <= encodedData.length / 2)`, issue with this is that this check does not allow the bootloader to correctly enforce that calls to this functiion would mostly fail due to the gas provided not being enough and might still cause the attempt to forcefully revert https://github.com/code-423n4/2024-03-zksync/blob/4f0ba34f34a864c354c7e8c47643ed8f4a250e13/code/system-contracts/bootloader/bootloader.yul#L1740-L1745 i.e an operator passing in a data that does not always fall as \"correct\" within the checks, for example say the new check of `dictionary.length / 8 <= encodedData.length / 2` is false, would lead to the `sendCompressedBytecode()` in the bootloader near calling and burning all the gas.\n\n### Impact\n\nHaving it in mind that the `sendCompressedBytecode()` function is called by the bootloader whenever there is a need for the L2 transaction to use packed bytecode as seen here https://github.com/code-423n4/2024-03-zksync/blob/4f0ba34f34a864c354c7e8c47643ed8f4a250e13/code/system-contracts/bootloader/bootloader.yul#L1506 , this then gives the operator the opportunity of burning all of the user's provided gas of any L2 transaction that needs packed/published bytecodes... potentially doing it constantly if the operator is malicious since all they need to do is tamper with the data they pass to the bootloader to ensure the compression always ends up malformed by ignoring the new `dictionary.length/8` check and then all users attempt just burn their gas.\n\n### Recommended Mitigation Steps\n\nSince this enforcement `dictionary.length / 8 <= encodedData.length / 2` still needs to be placed so as not to allow operator pass in an excessive length, then the near calling should be scrapped from the bootloader when an attempt to `sendCompressedBytecode()` is made, i.e if the compression is malformed the attempt should instead revert with reason rather than burning all the gas.\n\n**Additional Notes**\n\n> NB: This wasn't intended to be a QA submission, but these lines exist in the readMe: https://github.com/code-423n4/2024-03-zksync/blob/4f0ba34f34a864c354c7e8c47643ed8f4a250e13/README.md#L31-L34\n\n```markdown\nValidator can provide inefficient bytecode compression\n\nIn the current implementation, the mechanism for bytecode compression is not strictly unambiguous. That means the validator has the flexibility to choose a less efficient compression for the bytecode to increase the deployment cost for the end user. Besides that, there is another non-fixed [issue](https://github.com/code-423n4/2023-10-zksync-findings/issues/805), that gives a way for the operator to forces the user to pay more for the bytecode compression or even burn all the transaction gas during bytecode compression verification.\n```\n\nNow we assume the above snippet makes this issue somewhat subjective as we could argue it makes it stand on the lines of being OOS, If all parties think otherwise then this should be upgraded.\n\n",
  "Impact": "LOW",
  "Source": "https://code4rena.com/reports/2024-03-zksync",
  "Code": [
    {
      "filename": "code/system-contracts/contracts/Compressor.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity 0.8.20;\n\nimport {ICompressor, OPERATION_BITMASK, LENGTH_BITS_OFFSET, MAX_ENUMERATION_INDEX_SIZE} from \"./interfaces/ICompressor.sol\";\nimport {ISystemContract} from \"./interfaces/ISystemContract.sol\";\nimport {Utils} from \"./libraries/Utils.sol\";\nimport {UnsafeBytesCalldata} from \"./libraries/UnsafeBytesCalldata.sol\";\nimport {EfficientCall} from \"./libraries/EfficientCall.sol\";\nimport {L1_MESSENGER_CONTRACT, INITIAL_WRITE_STARTING_POSITION, COMPRESSED_INITIAL_WRITE_SIZE, STATE_DIFF_ENTRY_SIZE, STATE_DIFF_ENUM_INDEX_OFFSET, STATE_DIFF_FINAL_VALUE_OFFSET, STATE_DIFF_DERIVED_KEY_OFFSET, DERIVED_KEY_LENGTH, VALUE_LENGTH, ENUM_INDEX_LENGTH, KNOWN_CODE_STORAGE_CONTRACT} from \"./Constants.sol\";\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Contract with code pertaining to compression for zkEVM; at the moment this is used for bytecode compression\n * and state diff compression validation.\n * @dev Every deployed bytecode/published state diffs in zkEVM should be publicly restorable from the L1 data availability.\n * For this reason, the user may request the sequencer to publish the original bytecode and mark it as known.\n * Or the user may compress the bytecode and publish it instead (fewer data onchain!). At the end of every L1 Batch\n * we publish pubdata, part of which contains the state diffs that occurred within the batch.\n */\ncontract Compressor is ICompressor, ISystemContract {\n    using UnsafeBytesCalldata for bytes;\n\n    /// @notice Verify the compressed bytecode and publish it on the L1.\n    /// @param _bytecode The original bytecode to be verified against.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    /// @return bytecodeHash The hash of the original bytecode.\n    /// @dev The dictionary is a sequence of 8-byte chunks, each of them has the associated index.\n    /// @dev The encoded data is a sequence of 2-byte chunks, each of them is an index of the dictionary.\n    /// @dev The compression algorithm works as follows:\n    ///     1. The original bytecode is split into 8-byte chunks.\n    ///     Since the bytecode size is always a multiple of 32, this is always possible.\n    ///     2. For each 8-byte chunk in the original bytecode:\n    ///         * If the chunk is not already in the dictionary, it is added to the dictionary array.\n    ///         * If the dictionary becomes overcrowded (2^16 + 1 elements), the compression process will fail.\n    ///         * The 2-byte index of the chunk in the dictionary is added to the encoded data.\n    /// @dev Currently, the method may be called only from the bootloader because the server is not ready to publish bytecodes\n    /// in internal transactions. However, in the future, we will allow everyone to publish compressed bytecodes.\n    /// @dev Read more about the compression: https://github.com/matter-labs/zksync-era/blob/main/docs/guides/advanced/compression.md\n    function publishCompressedBytecode(\n        bytes calldata _bytecode,\n        bytes calldata _rawCompressedData\n    ) external payable onlyCallFromBootloader returns (bytes32 bytecodeHash) {\n        unchecked {\n            (bytes calldata dictionary, bytes calldata encodedData) = _decodeRawBytecode(_rawCompressedData);\n\n            require(\n                encodedData.length * 4 == _bytecode.length,\n                \"Encoded data length should be 4 times shorter than the original bytecode\"\n            );\n\n            require(\n                dictionary.length / 8 <= encodedData.length / 2,\n                \"Dictionary should have at most the same number of entries as the encoded data\"\n            );\n\n            for (uint256 encodedDataPointer = 0; encodedDataPointer < encodedData.length; encodedDataPointer += 2) {\n                uint256 indexOfEncodedChunk = uint256(encodedData.readUint16(encodedDataPointer)) * 8;\n                require(indexOfEncodedChunk < dictionary.length, \"Encoded chunk index is out of bounds\");\n\n                uint64 encodedChunk = dictionary.readUint64(indexOfEncodedChunk);\n                uint64 realChunk = _bytecode.readUint64(encodedDataPointer * 4);\n\n                require(encodedChunk == realChunk, \"Encoded chunk does not match the original bytecode\");\n            }\n        }\n\n        bytecodeHash = Utils.hashL2Bytecode(_bytecode);\n        L1_MESSENGER_CONTRACT.sendToL1(_rawCompressedData);\n        KNOWN_CODE_STORAGE_CONTRACT.markBytecodeAsPublished(bytecodeHash);\n    }\n\n    /// @notice Verifies that the compression of state diffs has been done correctly for the {_stateDiffs} param.\n    /// @param _numberOfStateDiffs The number of state diffs being checked.\n    /// @param _enumerationIndexSize Number of bytes used to represent an enumeration index for repeated writes.\n    /// @param _stateDiffs Encoded full state diff structs. See the first dev comment below for encoding.\n    /// @param _compressedStateDiffs The compressed state diffs\n    /// @dev We don't verify that the size of {_stateDiffs} is equivalent to {_numberOfStateDiffs} * STATE_DIFF_ENTRY_SIZE since that check is\n    ///      done within the L1Messenger calling contract.\n    /// @return stateDiffHash Hash of the encoded (uncompressed) state diffs to be committed to via system log.\n    /// @dev This check assumes that the ordering of state diffs are sorted by (address, key) for the encoded state diffs and\n    ///      then the compressed are sorted the same but with all the initial writes coming before the repeated writes.\n    /// @dev state diff:   [20bytes address][32bytes key][32bytes derived key][8bytes enum index][32bytes initial value][32bytes final value]\n    /// @dev The compression format:\n    ///     - 2 bytes: number of initial writes\n    ///     - N bytes initial writes\n    ///         - 32 bytes derived key\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    ///     - M bytes repeated writes\n    ///         - {_enumerationIndexSize} bytes for enumeration index\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    function verifyCompressedStateDiffs(\n        uint256 _numberOfStateDiffs,\n        uint256 _enumerationIndexSize,\n        bytes calldata _stateDiffs,\n        bytes calldata _compressedStateDiffs\n    ) external payable onlyCallFrom(address(L1_MESSENGER_CONTRACT)) returns (bytes32 stateDiffHash) {\n        // We do not enforce the operator to use the optimal, i.e. the minimally possible _enumerationIndexSize.\n        // We do enforce however, that the _enumerationIndexSize is not larger than 8 bytes long, which is the\n        // maximal ever possible size for enumeration index.\n        require(_enumerationIndexSize <= MAX_ENUMERATION_INDEX_SIZE, \"enumeration index size is too large\");\n\n        uint256 numberOfInitialWrites = uint256(_compressedStateDiffs.readUint16(0));\n\n        uint256 stateDiffPtr = 2;\n        uint256 numInitialWritesProcessed = 0;\n\n        // Process initial writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex != 0) {\n                // It is a repeated write, so we skip it.\n                continue;\n            }\n\n            numInitialWritesProcessed++;\n\n            bytes32 derivedKey = stateDiff.readBytes32(52);\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            require(derivedKey == _compressedStateDiffs.readBytes32(stateDiffPtr), \"iw: initial key mismatch\");\n            stateDiffPtr += 32;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr++;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(numInitialWritesProcessed == numberOfInitialWrites, \"Incorrect number of initial storage diffs\");\n\n        // Process repeated writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex == 0) {\n                continue;\n            }\n\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            uint256 compressedEnumIndex = _sliceToUint256(\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + _enumerationIndexSize]\n            );\n            require(enumIndex == compressedEnumIndex, \"rw: enum key mismatch\");\n            stateDiffPtr += _enumerationIndexSize;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr += 1;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(stateDiffPtr == _compressedStateDiffs.length, \"Extra data in _compressedStateDiffs\");\n\n        stateDiffHash = EfficientCall.keccak(_stateDiffs);\n    }\n\n    /// @notice Decode the raw compressed data into the dictionary and the encoded data.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the bytes length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    function _decodeRawBytecode(\n        bytes calldata _rawCompressedData\n    ) internal pure returns (bytes calldata dictionary, bytes calldata encodedData) {\n        unchecked {\n            // The dictionary length can't be more than 2^16, so it fits into 2 bytes.\n            uint256 dictionaryLen = uint256(_rawCompressedData.readUint16(0));\n            dictionary = _rawCompressedData[2:2 + dictionaryLen * 8];\n            encodedData = _rawCompressedData[2 + dictionaryLen * 8:];\n        }\n    }\n\n    /// @notice Verify value compression was done correct given initial value, final value, operation, and compressed value\n    /// @param _initialValue Previous value of key/enumeration index.\n    /// @param _finalValue Updated value of key/enumeration index.\n    /// @param _operation The operation that was performed on value.\n    /// @param _compressedValue The slice of calldata with compressed value either representing the final\n    /// value or difference between initial and final value. It should be of arbitrary length less than or equal to 32 bytes.\n    /// @dev It is the responsibility of the caller of this function to ensure that the `_compressedValue` has length no longer than 32 bytes.\n    /// @dev Operation id mapping:\n    /// 0 -> Nothing (32 bytes)\n    /// 1 -> Add\n    /// 2 -> Subtract\n    /// 3 -> Transform (< 32 bytes)\n    function _verifyValueCompression(\n        uint256 _initialValue,\n        uint256 _finalValue,\n        uint256 _operation,\n        bytes calldata _compressedValue\n    ) internal pure {\n        uint256 convertedValue = _sliceToUint256(_compressedValue);\n\n        unchecked {\n            if (_operation == 0 || _operation == 3) {\n                require(convertedValue == _finalValue, \"transform or no compression: compressed and final mismatch\");\n            } else if (_operation == 1) {\n                require(\n                    _initialValue + convertedValue == _finalValue,\n                    \"add: initial plus converted not equal to final\"\n                );\n            } else if (_operation == 2) {\n                require(\n                    _initialValue - convertedValue == _finalValue,\n                    \"sub: initial minus converted not equal to final\"\n                );\n            } else {\n                revert(\"unsupported operation\");\n            }\n        }\n    }\n\n    /// @notice Converts a calldata slice into uint256. It is the responsibility of the caller to ensure that\n    /// the _calldataSlice has length no longer than 32 bytes\n    /// @param _calldataSlice The calldata slice to convert to uint256\n    /// @return number The uint256 representation of the calldata slice\n    function _sliceToUint256(bytes calldata _calldataSlice) internal pure returns (uint256 number) {\n        number = uint256(bytes32(_calldataSlice));\n        number >>= (256 - (_calldataSlice.length * 8));\n    }\n}"
    },
    {
      "filename": "code/system-contracts/contracts/Compressor.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity 0.8.20;\n\nimport {ICompressor, OPERATION_BITMASK, LENGTH_BITS_OFFSET, MAX_ENUMERATION_INDEX_SIZE} from \"./interfaces/ICompressor.sol\";\nimport {ISystemContract} from \"./interfaces/ISystemContract.sol\";\nimport {Utils} from \"./libraries/Utils.sol\";\nimport {UnsafeBytesCalldata} from \"./libraries/UnsafeBytesCalldata.sol\";\nimport {EfficientCall} from \"./libraries/EfficientCall.sol\";\nimport {L1_MESSENGER_CONTRACT, INITIAL_WRITE_STARTING_POSITION, COMPRESSED_INITIAL_WRITE_SIZE, STATE_DIFF_ENTRY_SIZE, STATE_DIFF_ENUM_INDEX_OFFSET, STATE_DIFF_FINAL_VALUE_OFFSET, STATE_DIFF_DERIVED_KEY_OFFSET, DERIVED_KEY_LENGTH, VALUE_LENGTH, ENUM_INDEX_LENGTH, KNOWN_CODE_STORAGE_CONTRACT} from \"./Constants.sol\";\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Contract with code pertaining to compression for zkEVM; at the moment this is used for bytecode compression\n * and state diff compression validation.\n * @dev Every deployed bytecode/published state diffs in zkEVM should be publicly restorable from the L1 data availability.\n * For this reason, the user may request the sequencer to publish the original bytecode and mark it as known.\n * Or the user may compress the bytecode and publish it instead (fewer data onchain!). At the end of every L1 Batch\n * we publish pubdata, part of which contains the state diffs that occurred within the batch.\n */\ncontract Compressor is ICompressor, ISystemContract {\n    using UnsafeBytesCalldata for bytes;\n\n    /// @notice Verify the compressed bytecode and publish it on the L1.\n    /// @param _bytecode The original bytecode to be verified against.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    /// @return bytecodeHash The hash of the original bytecode.\n    /// @dev The dictionary is a sequence of 8-byte chunks, each of them has the associated index.\n    /// @dev The encoded data is a sequence of 2-byte chunks, each of them is an index of the dictionary.\n    /// @dev The compression algorithm works as follows:\n    ///     1. The original bytecode is split into 8-byte chunks.\n    ///     Since the bytecode size is always a multiple of 32, this is always possible.\n    ///     2. For each 8-byte chunk in the original bytecode:\n    ///         * If the chunk is not already in the dictionary, it is added to the dictionary array.\n    ///         * If the dictionary becomes overcrowded (2^16 + 1 elements), the compression process will fail.\n    ///         * The 2-byte index of the chunk in the dictionary is added to the encoded data.\n    /// @dev Currently, the method may be called only from the bootloader because the server is not ready to publish bytecodes\n    /// in internal transactions. However, in the future, we will allow everyone to publish compressed bytecodes.\n    /// @dev Read more about the compression: https://github.com/matter-labs/zksync-era/blob/main/docs/guides/advanced/compression.md\n    function publishCompressedBytecode(\n        bytes calldata _bytecode,\n        bytes calldata _rawCompressedData\n    ) external payable onlyCallFromBootloader returns (bytes32 bytecodeHash) {\n        unchecked {\n            (bytes calldata dictionary, bytes calldata encodedData) = _decodeRawBytecode(_rawCompressedData);\n\n            require(\n                encodedData.length * 4 == _bytecode.length,\n                \"Encoded data length should be 4 times shorter than the original bytecode\"\n            );\n\n            require(\n                dictionary.length / 8 <= encodedData.length / 2,\n                \"Dictionary should have at most the same number of entries as the encoded data\"\n            );\n\n            for (uint256 encodedDataPointer = 0; encodedDataPointer < encodedData.length; encodedDataPointer += 2) {\n                uint256 indexOfEncodedChunk = uint256(encodedData.readUint16(encodedDataPointer)) * 8;\n                require(indexOfEncodedChunk < dictionary.length, \"Encoded chunk index is out of bounds\");\n\n                uint64 encodedChunk = dictionary.readUint64(indexOfEncodedChunk);\n                uint64 realChunk = _bytecode.readUint64(encodedDataPointer * 4);\n\n                require(encodedChunk == realChunk, \"Encoded chunk does not match the original bytecode\");\n            }\n        }\n\n        bytecodeHash = Utils.hashL2Bytecode(_bytecode);\n        L1_MESSENGER_CONTRACT.sendToL1(_rawCompressedData);\n        KNOWN_CODE_STORAGE_CONTRACT.markBytecodeAsPublished(bytecodeHash);\n    }\n\n    /// @notice Verifies that the compression of state diffs has been done correctly for the {_stateDiffs} param.\n    /// @param _numberOfStateDiffs The number of state diffs being checked.\n    /// @param _enumerationIndexSize Number of bytes used to represent an enumeration index for repeated writes.\n    /// @param _stateDiffs Encoded full state diff structs. See the first dev comment below for encoding.\n    /// @param _compressedStateDiffs The compressed state diffs\n    /// @dev We don't verify that the size of {_stateDiffs} is equivalent to {_numberOfStateDiffs} * STATE_DIFF_ENTRY_SIZE since that check is\n    ///      done within the L1Messenger calling contract.\n    /// @return stateDiffHash Hash of the encoded (uncompressed) state diffs to be committed to via system log.\n    /// @dev This check assumes that the ordering of state diffs are sorted by (address, key) for the encoded state diffs and\n    ///      then the compressed are sorted the same but with all the initial writes coming before the repeated writes.\n    /// @dev state diff:   [20bytes address][32bytes key][32bytes derived key][8bytes enum index][32bytes initial value][32bytes final value]\n    /// @dev The compression format:\n    ///     - 2 bytes: number of initial writes\n    ///     - N bytes initial writes\n    ///         - 32 bytes derived key\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    ///     - M bytes repeated writes\n    ///         - {_enumerationIndexSize} bytes for enumeration index\n    ///         - 1 byte metadata:\n    ///             - first 5 bits: length in bytes of compressed value\n    ///             - last 3 bits: operation\n    ///                 - 0 -> Nothing (32 bytes)\n    ///                 - 1 -> Add\n    ///                 - 2 -> Subtract\n    ///                 - 3 -> Transform (< 32 bytes)\n    ///         - Len Bytes: Compressed Value\n    function verifyCompressedStateDiffs(\n        uint256 _numberOfStateDiffs,\n        uint256 _enumerationIndexSize,\n        bytes calldata _stateDiffs,\n        bytes calldata _compressedStateDiffs\n    ) external payable onlyCallFrom(address(L1_MESSENGER_CONTRACT)) returns (bytes32 stateDiffHash) {\n        // We do not enforce the operator to use the optimal, i.e. the minimally possible _enumerationIndexSize.\n        // We do enforce however, that the _enumerationIndexSize is not larger than 8 bytes long, which is the\n        // maximal ever possible size for enumeration index.\n        require(_enumerationIndexSize <= MAX_ENUMERATION_INDEX_SIZE, \"enumeration index size is too large\");\n\n        uint256 numberOfInitialWrites = uint256(_compressedStateDiffs.readUint16(0));\n\n        uint256 stateDiffPtr = 2;\n        uint256 numInitialWritesProcessed = 0;\n\n        // Process initial writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex != 0) {\n                // It is a repeated write, so we skip it.\n                continue;\n            }\n\n            numInitialWritesProcessed++;\n\n            bytes32 derivedKey = stateDiff.readBytes32(52);\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            require(derivedKey == _compressedStateDiffs.readBytes32(stateDiffPtr), \"iw: initial key mismatch\");\n            stateDiffPtr += 32;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr++;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(numInitialWritesProcessed == numberOfInitialWrites, \"Incorrect number of initial storage diffs\");\n\n        // Process repeated writes\n        for (uint256 i = 0; i < _numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE; i += STATE_DIFF_ENTRY_SIZE) {\n            bytes calldata stateDiff = _stateDiffs[i:i + STATE_DIFF_ENTRY_SIZE];\n            uint64 enumIndex = stateDiff.readUint64(84);\n            if (enumIndex == 0) {\n                continue;\n            }\n\n            uint256 initValue = stateDiff.readUint256(92);\n            uint256 finalValue = stateDiff.readUint256(124);\n            uint256 compressedEnumIndex = _sliceToUint256(\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + _enumerationIndexSize]\n            );\n            require(enumIndex == compressedEnumIndex, \"rw: enum key mismatch\");\n            stateDiffPtr += _enumerationIndexSize;\n\n            uint8 metadata = uint8(bytes1(_compressedStateDiffs[stateDiffPtr]));\n            stateDiffPtr += 1;\n            uint8 operation = metadata & OPERATION_BITMASK;\n            uint8 len = operation == 0 ? 32 : metadata >> LENGTH_BITS_OFFSET;\n            _verifyValueCompression(\n                initValue,\n                finalValue,\n                operation,\n                _compressedStateDiffs[stateDiffPtr:stateDiffPtr + len]\n            );\n            stateDiffPtr += len;\n        }\n\n        require(stateDiffPtr == _compressedStateDiffs.length, \"Extra data in _compressedStateDiffs\");\n\n        stateDiffHash = EfficientCall.keccak(_stateDiffs);\n    }\n\n    /// @notice Decode the raw compressed data into the dictionary and the encoded data.\n    /// @param _rawCompressedData The compressed bytecode in a format of:\n    ///    - 2 bytes: the bytes length of the dictionary\n    ///    - N bytes: the dictionary\n    ///    - M bytes: the encoded data\n    function _decodeRawBytecode(\n        bytes calldata _rawCompressedData\n    ) internal pure returns (bytes calldata dictionary, bytes calldata encodedData) {\n        unchecked {\n            // The dictionary length can't be more than 2^16, so it fits into 2 bytes.\n            uint256 dictionaryLen = uint256(_rawCompressedData.readUint16(0));\n            dictionary = _rawCompressedData[2:2 + dictionaryLen * 8];\n            encodedData = _rawCompressedData[2 + dictionaryLen * 8:];\n        }\n    }\n\n    /// @notice Verify value compression was done correct given initial value, final value, operation, and compressed value\n    /// @param _initialValue Previous value of key/enumeration index.\n    /// @param _finalValue Updated value of key/enumeration index.\n    /// @param _operation The operation that was performed on value.\n    /// @param _compressedValue The slice of calldata with compressed value either representing the final\n    /// value or difference between initial and final value. It should be of arbitrary length less than or equal to 32 bytes.\n    /// @dev It is the responsibility of the caller of this function to ensure that the `_compressedValue` has length no longer than 32 bytes.\n    /// @dev Operation id mapping:\n    /// 0 -> Nothing (32 bytes)\n    /// 1 -> Add\n    /// 2 -> Subtract\n    /// 3 -> Transform (< 32 bytes)\n    function _verifyValueCompression(\n        uint256 _initialValue,\n        uint256 _finalValue,\n        uint256 _operation,\n        bytes calldata _compressedValue\n    ) internal pure {\n        uint256 convertedValue = _sliceToUint256(_compressedValue);\n\n        unchecked {\n            if (_operation == 0 || _operation == 3) {\n                require(convertedValue == _finalValue, \"transform or no compression: compressed and final mismatch\");\n            } else if (_operation == 1) {\n                require(\n                    _initialValue + convertedValue == _finalValue,\n                    \"add: initial plus converted not equal to final\"\n                );\n            } else if (_operation == 2) {\n                require(\n                    _initialValue - convertedValue == _finalValue,\n                    \"sub: initial minus converted not equal to final\"\n                );\n            } else {\n                revert(\"unsupported operation\");\n            }\n        }\n    }\n\n    /// @notice Converts a calldata slice into uint256. It is the responsibility of the caller to ensure that\n    /// the _calldataSlice has length no longer than 32 bytes\n    /// @param _calldataSlice The calldata slice to convert to uint256\n    /// @return number The uint256 representation of the calldata slice\n    function _sliceToUint256(bytes calldata _calldataSlice) internal pure returns (uint256 number) {\n        number = uint256(bytes32(_calldataSlice));\n        number >>= (256 - (_calldataSlice.length * 8));\n    }\n}"
    },
    {
      "filename": "code/system-contracts/bootloader/bootloader.yul",
      "content": "object \"Bootloader\" {\n    code {\n    }\n    object \"Bootloader_deployed\" {\n        code {\n            {{CODE_START_PLACEHOLDER}}\n\n            ////////////////////////////////////////////////////////////////////////////\n            //                      Function Declarations\n            ////////////////////////////////////////////////////////////////////////////\n\n            // While we definitely cannot control the pubdata price on L1,\n            // we need to check the operator does not provide any absurd numbers there\n            function MAX_ALLOWED_FAIR_PUBDATA_PRICE() -> ret {\n                // 1M gwei\n                ret := 1000000000000000\n            }\n\n            function MAX_ALLOWED_FAIR_L2_GAS_PRICE() -> ret {\n                // 10k gwei\n                ret := 10000000000000\n            }\n\n            /// @dev This method ensures that the prices provided by the operator\n            /// are not absurdly high\n            function validateOperatorProvidedPrices(fairL2GasPrice, pubdataPrice) {\n                // The limit is the same for pubdata price and L1 gas price\n                if gt(pubdataPrice, MAX_ALLOWED_FAIR_PUBDATA_PRICE()) {\n                    assertionError(\"Fair pubdata price too high\")\n                }\n\n                if gt(fairL2GasPrice, MAX_ALLOWED_FAIR_L2_GAS_PRICE()) {\n                    assertionError(\"L2 fair gas price too high\")\n                }\n            }\n\n            /// @dev The overhead for a transaction slot in L2 gas. \n            /// It is roughly equal to 80kk/MAX_TRANSACTIONS_IN_BATCH, i.e. how many gas would an L1->L2 transaction\n            /// need to pay to compensate for the batch being closed.\n            /// @dev It is expected of the operator to set the \"fair L2 gas price\" appropriately to ensure that it is \n            /// compensated enough in case the batch might be prematurely sealed because of the transaction slots being filled up.\n            function TX_SLOT_OVERHEAD_GAS() -> ret {\n                ret := 10000\n            }\n\n            /// @dev The overhead for each byte of the bootloader memory that the encoding of the transaction.\n            /// It is roughly equal to 80kk/BOOTLOADER_MEMORY_FOR_TXS, i.e. how many gas would an L1->L2 transaction\n            /// need to pay to compensate for the batch being closed.\n            /// @dev It is expected of the operator to set the \"fair L2 gas price\" appropriately to ensure that it is\n            /// compensated enough in case the batch might be prematurely sealed because of the memory being filled up.\n            function MEMORY_OVERHEAD_GAS() -> ret {\n                ret := 10\n            }\n\n            /// @dev Returns the base fee and gas per pubdata based on the fair pubdata price and L2 gas price provided by the operator\n            /// @param pubdataPrice The price of a single byte of pubdata in Wei\n            /// @param fairL2GasPrice The price of an L2 gas in Wei\n            /// @return baseFee and gasPerPubdata The base fee and the gas per pubdata to be used by L2 transactions in this batch.\n            function getFeeParams(\n                fairPubdataPrice,\n                fairL2GasPrice,\n            ) -> baseFee, gasPerPubdata {\n                baseFee := max(\n                    fairL2GasPrice,\n                    ceilDiv(fairPubdataPrice, MAX_L2_GAS_PER_PUBDATA())\n                )\n\n                gasPerPubdata := gasPerPubdataFromBaseFee(baseFee, fairPubdataPrice)\n            }\n\n            /// @dev Calculates the gas per pubdata based on the pubdata price provided by the operator\n            /// as well the the fixed baseFee.\n            function gasPerPubdataFromBaseFee(baseFee, pubdataPrice) -> ret {\n                ret := ceilDiv(pubdataPrice, baseFee)\n            }\n\n            /// @dev It should be always possible to submit a transaction \n            /// that consumes such amount of public data.\n            function GUARANTEED_PUBDATA_PER_TX() -> ret {\n                ret := {{GUARANTEED_PUBDATA_BYTES}}\n            }\n\n            /// @dev The maximal allowed gasPerPubdata, we want it multiplied by the u32::MAX \n            /// (i.e. the maximal possible value of the pubdata counter) to be a safe JS integer with a good enough margin.\n            function MAX_L2_GAS_PER_PUBDATA() -> ret {\n                ret := 1048576\n            }\n\n            /// @dev The overhead for the interaction with L1.\n            /// It should cover proof verification as well as other minor \n            /// overheads for committing/executing a transaction in a batch.\n            function BATCH_OVERHEAD_L1_GAS() -> ret {\n                ret := {{BATCH_OVERHEAD_L1_GAS}}\n            }\n\n            /// @dev The maximal number of gas available to the transaction\n            function MAX_GAS_PER_TRANSACTION() -> ret {\n                ret := {{MAX_GAS_PER_TRANSACTION}}\n            }\n\n            /// @dev The number of L1 gas needed to be spent for\n            /// L1 byte. While a single pubdata byte costs `16` gas, \n            /// we demand at least 17 to cover up for the costs of additional\n            /// hashing of it, etc.\n            function L1_GAS_PER_PUBDATA_BYTE() -> ret {\n                r"
    }
  ]
}