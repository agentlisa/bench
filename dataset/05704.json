{
  "Title": "[17] Tautology in `publishPubdataAndClearState`",
  "Content": "\nIn [L1Messenger, function `publishPubdataAndClearState`](https://github.com/code-423n4/2023-10-zksync/blob/1fb4649b612fac7b4ee613df6f6b7d921ddd6b0d/code/system-contracts/contracts/L1Messenger.sol#L206) there is a tautology:\n\n```solidity\n        require(numberOfL2ToL1Logs <= numberOfL2ToL1Logs, \"Too many L2->L1 logs\");\n```\n\nAs `numberOfL2ToL1Logs <= numberOfL2ToL1Logs` always holds, it can pass more logs than `numberOfLogsToProcess`. However, the correctness of the amount of sent logs is also checked in\n\n[Executor, lines 166 to 170](https://github.com/code-423n4/2023-10-zksync/blob/1fb4649b612fac7b4ee613df6f6b7d921ddd6b0d/code/contracts/ethereum/contracts/zksync/facets/Executor.sol#L166C1-L170C10)\n\n```solidity\n        if (_expectedSystemContractUpgradeTxHash == bytes32(0)) {\n            require(processedLogs == 127, \"b7\");\n        } else {\n            require(processedLogs == 255, \"b8\");\n        }\n```\n\nNOTE: I did not test it, but it seems it lets the door open for the operator to add an additional log to the queue if there was a system upgrade, so that the first condition reverts, which may be considered as a temporal DOS/griefing. Consider changing to:\n\n```diff\n-        require(numberOfL2ToL1Logs <= numberOfL2ToL1Logs, \"Too many L2->L1 logs\");\n+        require(numberOfL2ToL1Logs <= numberOfLogsToProcess, \"Too many L2->L1 logs\");\n```\n\n",
  "Impact": "LOW",
  "Source": "https://code4rena.com/reports/2023-10-zksync",
  "Code": [
    {
      "filename": "code/system-contracts/contracts/L1Messenger.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity ^0.8.0;\n\nimport {IL1Messenger, L2ToL1Log, L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH, L2_TO_L1_LOG_SERIALIZE_SIZE, STATE_DIFF_COMPRESSION_VERSION_NUMBER} from \"./interfaces/IL1Messenger.sol\";\nimport {ISystemContract} from \"./interfaces/ISystemContract.sol\";\nimport {SystemContractHelper} from \"./libraries/SystemContractHelper.sol\";\nimport {EfficientCall} from \"./libraries/EfficientCall.sol\";\nimport {Utils} from \"./libraries/Utils.sol\";\nimport {\n    SystemLogKey,\n    SYSTEM_CONTEXT_CONTRACT,\n    KNOWN_CODE_STORAGE_CONTRACT,\n    COMPRESSOR_CONTRACT,\n    STATE_DIFF_ENTRY_SIZE,\n    MAX_ALLOWED_PUBDATA_PER_BATCH,\n    L2_TO_L1_LOGS_MERKLE_TREE_LEAVES\n} from \"./Constants.sol\";\n\n/**\n * @author Matter Labs\n * @custom:security-contact security@matterlabs.dev\n * @notice Smart contract for sending arbitrary length messages to L1\n * @dev by default ZkSync can send fixed length messages on L1.\n * A fixed length message has 4 parameters `senderAddress` `isService`, `key`, `value`,\n * the first one is taken from the context, the other three are chosen by the sender.\n * @dev To send a variable length message we use this trick:\n * - This system contract accepts a arbitrary length message and sends a fixed length message with\n * parameters `senderAddress == this`, `marker == true`, `key == msg.sender`, `value == keccak256(message)`.\n * - The contract on L1 accepts all sent messages and if the message came from this system contract\n * it requires that the preimage of `value` be provided.\n */\ncontract L1Messenger is IL1Messenger, ISystemContract {\n    /// @notice Sequential hash of logs sent in the current block.\n    /// @dev Will be reset at the end of the block to zero value.\n    bytes32 internal chainedLogsHash;\n\n    /// @notice Number of logs sent in the current block.\n    /// @dev Will be reset at the end of the block to zero value.\n    uint256 internal numberOfLogsToProcess;\n\n    /// @notice Sequential hash of hashes of the messages sent in the current block.\n    /// @dev Will be reset at the end of the block to zero value.\n    bytes32 internal chainedMessagesHash;\n\n    /// @notice Sequential hash of bytecode hashes that needs to published\n    /// according to the current block execution invariant.\n    /// @dev Will be reset at the end of the block to zero value.\n    bytes32 internal chainedL1BytecodesRevealDataHash;\n\n    /// The gas cost of processing one keccak256 round.\n    uint256 internal constant KECCAK_ROUND_GAS_COST = 40;\n\n    /// The number of bytes processed in one keccak256 round.\n    uint256 internal constant KECCAK_ROUND_NUMBER_OF_BYTES = 136;\n\n    /// The gas cost of calculation of keccak256 of bytes array of such length.\n    function keccakGasCost(uint256 _length) internal pure returns (uint256) {\n        return KECCAK_ROUND_GAS_COST * (_length / KECCAK_ROUND_NUMBER_OF_BYTES + 1);\n    }\n\n    /// The gas cost of processing one sha256 round.\n    uint256 internal constant SHA256_ROUND_GAS_COST = 7;\n\n    /// The number of bytes processed in one sha256 round.\n    uint256 internal constant SHA256_ROUND_NUMBER_OF_BYTES = 64;\n\n    /// The gas cost of calculation of sha256 of bytes array of such length.\n    function sha256GasCost(uint256 _length) internal pure returns (uint256) {\n        return SHA256_ROUND_GAS_COST * ((_length + 8) / SHA256_ROUND_NUMBER_OF_BYTES + 1);\n    }\n\n    /// @notice Sends L2ToL1Log.\n    /// @dev Can be called only by a system contract.\n    function sendL2ToL1Log(\n        bool _isService,\n        bytes32 _key,\n        bytes32 _value\n    ) external onlyCallFromSystemContract returns (uint256 logIdInMerkleTree) {\n        L2ToL1Log memory l2ToL1Log = L2ToL1Log({\n            l2ShardId: 0,\n            isService: _isService,\n            txNumberInBlock: SYSTEM_CONTEXT_CONTRACT.txNumberInBlock(),\n            sender: msg.sender,\n            key: _key,\n            value: _value\n        });\n        logIdInMerkleTree = _processL2ToL1Log(l2ToL1Log);\n\n        // We need to charge cost of hashing, as it will be used in `publishPubdataAndClearState`:\n        // - keccakGasCost(L2_TO_L1_LOG_SERIALIZE_SIZE) and keccakGasCost(64) when reconstructing L2ToL1Log\n        // - at most 2 times keccakGasCost(64) (as merkle tree can contain ~2*N leaves)\n        uint256 gasToPay = keccakGasCost(L2_TO_L1_LOG_SERIALIZE_SIZE) + 3 * keccakGasCost(64);\n        SystemContractHelper.burnGas(Utils.safeCastToU32(gasToPay));\n    }\n\n    /// @notice Internal function to send L2ToL1Log.\n    function _processL2ToL1Log(L2ToL1Log memory _l2ToL1Log) internal returns (uint256 logIdInMerkleTree) {\n        bytes32 hashedLog = keccak256(\n            abi.encodePacked(\n                _l2ToL1Log.l2ShardId,\n                _l2ToL1Log.isService,\n                _l2ToL1Log.txNumberInBlock,\n                _l2ToL1Log.sender,\n                _l2ToL1Log.key,\n                _l2ToL1Log.value\n            )\n        );\n\n        chainedLogsHash = keccak256(abi.encode(chainedLogsHash, hashedLog));\n\n        logIdInMerkleTree = numberOfLogsToProcess;\n        numberOfLogsToProcess++;\n\n        emit L2ToL1LogSent(_l2ToL1Log);\n    }\n\n    /// @notice Public functionality to send messages to L1.\n    function sendToL1(bytes calldata _message) external override returns (bytes32 hash) {\n        uint256 gasBeforeMessageHashing = gasleft();\n        hash = EfficientCall.keccak(_message);\n        uint256 gasSpentOnMessageHashing = gasBeforeMessageHashing - gasleft();\n\n        /// Store message record\n        chainedMessagesHash = keccak256(abi.encode(chainedMessagesHash, hash));\n\n        /// Store log record\n        L2ToL1Log memory l2ToL1Log = L2ToL1Log({\n            l2ShardId: 0,\n            isService: true,\n            txNumberInBlock: SYSTEM_CONTEXT_CONTRACT.txNumberInBlock(),\n            sender: address(this),\n            key: bytes32(uint256(uint160(msg.sender))),\n            value: hash\n        });\n        _processL2ToL1Log(l2ToL1Log);\n\n        // Get cost of one byte pubdata in gas from context.\n        uint256 meta = SystemContractHelper.getZkSyncMetaBytes();\n        uint32 gasPerPubdataBytes = SystemContractHelper.getGasPerPubdataByteFromMeta(meta);\n\n        uint256 pubdataLen;\n        unchecked {\n            // 4 bytes used to encode the length of the message (see `publishPubdataAndClearState`)\n            // L2_TO_L1_LOG_SERIALIZE_SIZE bytes used to encode L2ToL1Log\n            pubdataLen = 4 + _message.length + L2_TO_L1_LOG_SERIALIZE_SIZE;\n        }\n\n        // We need to charge cost of hashing, as it will be used in `publishPubdataAndClearState`:\n        // - keccakGasCost(L2_TO_L1_LOG_SERIALIZE_SIZE) and keccakGasCost(64) when reconstructing L2ToL1Log\n        // - keccakGasCost(64) and gasSpentOnMessageHashing when reconstructing Messages\n        // - at most 2 times keccakGasCost(64) (as merkle tree can contain ~2*N leaves)\n        uint256 gasToPay = pubdataLen *\n            gasPerPubdataBytes +\n            keccakGasCost(L2_TO_L1_LOG_SERIALIZE_SIZE) +\n            4 *\n            keccakGasCost(64) +\n            gasSpentOnMessageHashing;\n        SystemContractHelper.burnGas(Utils.safeCastToU32(gasToPay));\n\n        emit L1MessageSent(msg.sender, hash, _message);\n    }\n\n    /// @dev Can be called only by KnownCodesStorage system contract.\n    function requestBytecodeL1Publication(\n        bytes32 _bytecodeHash\n    ) external override onlyCallFrom(address(KNOWN_CODE_STORAGE_CONTRACT)) {\n        chainedL1BytecodesRevealDataHash = keccak256(abi.encode(chainedL1BytecodesRevealDataHash, _bytecodeHash));\n\n        uint256 bytecodeLen = Utils.bytecodeLenInBytes(_bytecodeHash);\n\n        // Get cost of one byte pubdata in gas from context.\n        uint256 meta = SystemContractHelper.getZkSyncMetaBytes();\n        uint32 gasPerPubdataBytes = SystemContractHelper.getGasPerPubdataByteFromMeta(meta);\n\n        uint256 pubdataLen;\n        unchecked {\n            // 4 bytes used to encode the length of the bytecode (see `publishPubdataAndClearState`)\n            pubdataLen = 4 + bytecodeLen;\n        }\n\n        // We need to charge cost of hashing, as it will be used in `publishPubdataAndClearState`\n        uint256 gasToPay = pubdataLen * gasPerPubdataBytes + sha256GasCost(bytecodeLen) + keccakGasCost(64);\n        SystemContractHelper.burnGas(Utils.safeCastToU32(gasToPay));\n\n        emit BytecodeL1PublicationRequested(_bytecodeHash);\n    }\n\n    /// @notice Verifies that the {_totalL2ToL1PubdataAndStateDiffs} reflects what occurred within the L1Batch and that\n    ///         the compressed statediffs are equivalent to the full state diffs.\n    /// @param _totalL2ToL1PubdataAndStateDiffs The total pubdata and uncompressed state diffs of transactions that were\n    ///        processed in the current L1 Batch. Pubdata consists of L2 to L1 Logs, messages, deployed bytecode, and state diffs.\n    /// @dev Function that should be called exactly once per L1 Batch by the bootloader.\n    /// @dev Checks that totalL2ToL1Pubdata is strictly packed data that should to be published to L1.\n    /// @dev The data passed in also contains the encoded state diffs to be checked again, however this is aux data that is not\n    ///      part of the committed pubdata.\n    /// @dev Performs calculation of L2ToL1Logs merkle tree root, \"sends\" such root and keccak256(totalL2ToL1Pubdata)\n    /// to L1 using low-level (VM) L2Log.\n    function publishPubdataAndClearState(\n        bytes calldata _totalL2ToL1PubdataAndStateDiffs\n    ) external onlyCallFromBootloader {\n        uint256 calldataPtr = 0;\n\n        /// Check logs\n        uint32 numberOfL2ToL1Logs = uint32(bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4]));\n        require(numberOfL2ToL1Logs <= numberOfL2ToL1Logs, \"Too many L2->L1 logs\");\n        calldataPtr += 4;\n\n        bytes32[] memory l2ToL1LogsTreeArray = new bytes32[](L2_TO_L1_LOGS_MERKLE_TREE_LEAVES);\n        bytes32 reconstructedChainedLogsHash;\n        for (uint256 i = 0; i < numberOfL2ToL1Logs; ++i) {\n            bytes32 hashedLog = EfficientCall.keccak(\n                _totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + L2_TO_L1_LOG_SERIALIZE_SIZE]\n            );\n            calldataPtr += L2_TO_L1_LOG_SERIALIZE_SIZE;\n            l2ToL1LogsTreeArray[i] = hashedLog;\n            reconstructedChainedLogsHash = keccak256(abi.encode(reconstructedChainedLogsHash, hashedLog));\n        }\n        require(\n            reconstructedChainedLogsHash == chainedLogsHash,\n            \"reconstructedChainedLogsHash is not equal to chainedLogsHash\"\n        );\n        for (uint256 i = numberOfL2ToL1Logs; i < L2_TO_L1_LOGS_MERKLE_TREE_LEAVES; ++i) {\n            l2ToL1LogsTreeArray[i] = L2_L1_LOGS_TREE_DEFAULT_LEAF_HASH;\n        }\n        uint256 nodesOnCurrentLevel = L2_TO_L1_LOGS_MERKLE_TREE_LEAVES;\n        while (nodesOnCurrentLevel > 1) {\n            nodesOnCurrentLevel /= 2;\n            for (uint256 i = 0; i < nodesOnCurrentLevel; ++i) {\n                l2ToL1LogsTreeArray[i] = keccak256(\n                    abi.encode(l2ToL1LogsTreeArray[2 * i], l2ToL1LogsTreeArray[2 * i + 1])\n                );\n            }\n        }\n        bytes32 l2ToL1LogsTreeRoot = l2ToL1LogsTreeArray[0];\n\n        /// Check messages\n        uint32 numberOfMessages = uint32(bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4]));\n        calldataPtr += 4;\n        bytes32 reconstructedChainedMessagesHash;\n        for (uint256 i = 0; i < numberOfMessages; ++i) {\n            uint32 currentMessageLength = uint32(bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4]));\n            calldataPtr += 4;\n            bytes32 hashedMessage = EfficientCall.keccak(\n                _totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + currentMessageLength]\n            );\n            calldataPtr += currentMessageLength;\n            reconstructedChainedMessagesHash = keccak256(abi.encode(reconstructedChainedMessagesHash, hashedMessage));\n        }\n        require(\n            reconstructedChainedMessagesHash == chainedMessagesHash,\n            \"reconstructedChainedMessagesHash is not equal to chainedMessagesHash\"\n        );\n\n        /// Check bytecodes\n        uint32 numberOfBytecodes = uint32(bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4]));\n        calldataPtr += 4;\n        bytes32 reconstructedChainedL1BytecodesRevealDataHash;\n        for (uint256 i = 0; i < numberOfBytecodes; ++i) {\n            uint32 currentBytecodeLength = uint32(\n                bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4])\n            );\n            calldataPtr += 4;\n            reconstructedChainedL1BytecodesRevealDataHash = keccak256(\n                abi.encode(\n                    reconstructedChainedL1BytecodesRevealDataHash,\n                    Utils.hashL2Bytecode(\n                        _totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + currentBytecodeLength]\n                    )\n                )\n            );\n            calldataPtr += currentBytecodeLength;\n        }\n        require(\n            reconstructedChainedL1BytecodesRevealDataHash == chainedL1BytecodesRevealDataHash,\n            \"reconstructedChainedL1BytecodesRevealDataHash is not equal to chainedL1BytecodesRevealDataHash\"\n        );\n\n        /// Check State Diffs\n        /// encoding is as follows:\n        /// header (1 byte version, 2 bytes total len of compressed, 1 byte enumeration index size, 2 bytes number of initial writes)\n        /// body (N bytes of initial writes [32 byte derived key || compressed value], M bytes repeated writes [enumeration index || compressed value])\n        /// encoded state diffs: [20bytes address][32bytes key][32bytes derived key][8bytes enum index][32bytes initial value][32bytes final value]\n        require(\n            uint256(uint8(bytes1(_totalL2ToL1PubdataAndStateDiffs[calldataPtr]))) ==\n                STATE_DIFF_COMPRESSION_VERSION_NUMBER,\n            \"state diff compression version mismatch\"\n        );\n        calldataPtr++;\n\n        uint24 compressedStateDiffSize = uint24(bytes3(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 3]));\n        calldataPtr += 3;\n\n        uint8 enumerationIndexSize = uint8(bytes1(_totalL2ToL1PubdataAndStateDiffs[calldataPtr]));\n        calldataPtr++;\n\n        bytes calldata compressedStateDiffs = _totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr +\n            compressedStateDiffSize];\n        calldataPtr += compressedStateDiffSize;\n\n        bytes calldata totalL2ToL1Pubdata = _totalL2ToL1PubdataAndStateDiffs[:calldataPtr];\n\n        require(calldataPtr <= MAX_ALLOWED_PUBDATA_PER_BATCH, \"L1 Messenger pubdata is too long\");\n\n        uint32 numberOfStateDiffs = uint32(bytes4(_totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr + 4]));\n        calldataPtr += 4;\n\n        bytes calldata stateDiffs = _totalL2ToL1PubdataAndStateDiffs[calldataPtr:calldataPtr +\n            (numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE)];\n        calldataPtr += numberOfStateDiffs * STATE_DIFF_ENTRY_SIZE;\n\n        bytes32 stateDiffHash = COMPRESSOR_CONTRACT.verifyCompressedStateDiffs(\n            numberOfStateDiffs,\n            enumerationIndexSize,\n            stateDiffs,\n            compressedStateDiffs\n        );\n\n        /// Check for calldata strict format\n        require(calldataPtr == _totalL2ToL1PubdataAndStateDiffs.length, \"Extra data in the totalL2ToL1Pubdata array\");\n\n        /// Native (VM) L2 to L1 log\n        SystemContractHelper.toL1(true, bytes32(uint256(SystemLogKey.L2_TO_L1_LOGS_TREE_ROOT_KEY)), l2ToL1LogsTreeRoot);\n        SystemContractHelper.toL1(\n            true,\n            bytes32(uint256(SystemLogKey.TOTAL_L2_TO_L1_PUBDATA_KEY)),\n            EfficientCall.keccak(totalL2ToL1Pubdata)\n        );\n        SystemContractHelper.toL1(true, bytes32(uint256(SystemLogKey.STATE_DIFF_HASH_KEY)), stateDiffHash);\n\n        /// Clear logs state\n        chainedLogsHash = bytes32(0);\n        numberOfLogsToProcess = 0;\n        chainedMessagesHash = bytes32(0);\n        chainedL1BytecodesRevealDataHash = bytes32(0);\n    }\n}"
    },
    {
      "filename": "code/contracts/ethereum/contracts/zksync/facets/Executor.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity ^0.8.13;\n\nimport {Base} from \"./Base.sol\";\nimport {COMMIT_TIMESTAMP_NOT_OLDER, COMMIT_TIMESTAMP_APPROXIMATION_DELTA, EMPTY_STRING_KECCAK, L2_TO_L1_LOG_SERIALIZE_SIZE, INPUT_MASK, MAX_INITIAL_STORAGE_CHANGES_COMMITMENT_BYTES, MAX_REPEATED_STORAGE_CHANGES_COMMITMENT_BYTES, MAX_L2_TO_L1_LOGS_COMMITMENT_BYTES, PACKED_L2_BLOCK_TIMESTAMP_MASK} from \"../Config.sol\";\nimport {IExecutor, L2_LOG_ADDRESS_OFFSET, L2_LOG_KEY_OFFSET, L2_LOG_VALUE_OFFSET, SystemLogKey} from \"../interfaces/IExecutor.sol\";\nimport {PriorityQueue, PriorityOperation} from \"../libraries/PriorityQueue.sol\";\nimport {UncheckedMath} from \"../../common/libraries/UncheckedMath.sol\";\nimport {UnsafeBytes} from \"../../common/libraries/UnsafeBytes.sol\";\nimport {L2ContractHelper} from \"../../common/libraries/L2ContractHelper.sol\";\nimport {VerifierParams} from \"../Storage.sol\";\nimport {L2_BOOTLOADER_ADDRESS, L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR, L2_SYSTEM_CONTEXT_SYSTEM_CONTRACT_ADDR, L2_KNOWN_CODE_STORAGE_SYSTEM_CONTRACT_ADDR} from \"../../common/L2ContractAddresses.sol\";\n\n/// @title zkSync Executor contract capable of processing events emitted in the zkSync protocol.\n/// @author Matter Labs\n/// @custom:security-contact security@matterlabs.dev\ncontract ExecutorFacet is Base, IExecutor {\n    using UncheckedMath for uint256;\n    using PriorityQueue for PriorityQueue.Queue;\n\n    string public constant override getName = \"ExecutorFacet\";\n\n    /// @dev Process one batch commit using the previous batch StoredBatchInfo\n    /// @dev returns new batch StoredBatchInfo\n    /// @notice Does not change storage\n    function _commitOneBatch(\n        StoredBatchInfo memory _previousBatch,\n        CommitBatchInfo calldata _newBatch,\n        bytes32 _expectedSystemContractUpgradeTxHash\n    ) internal view returns (StoredBatchInfo memory) {\n        require(_newBatch.batchNumber == _previousBatch.batchNumber + 1, \"f\"); // only commit next batch\n\n        // Check that batch contain all meta information for L2 logs.\n        // Get the chained hash of priority transaction hashes.\n        (\n            uint256 expectedNumberOfLayer1Txs,\n            bytes32 expectedPriorityOperationsHash,\n            bytes32 previousBatchHash,\n            bytes32 stateDiffHash,\n            bytes32 l2LogsTreeRoot,\n            uint256 packedBatchAndL2BlockTimestamp\n        ) = _processL2Logs(_newBatch, _expectedSystemContractUpgradeTxHash);\n\n        require(_previousBatch.batchHash == previousBatchHash, \"l\");\n        // Check that the priority operation hash in the L2 logs is as expected\n        require(expectedPriorityOperationsHash == _newBatch.priorityOperationsHash, \"t\");\n        // Check that the number of processed priority operations is as expected\n        require(expectedNumberOfLayer1Txs == _newBatch.numberOfLayer1Txs, \"ta\");\n\n        // Check the timestamp of the new batch\n        _verifyBatchTimestamp(packedBatchAndL2BlockTimestamp, _newBatch.timestamp, _previousBatch.timestamp);\n\n        // Create batch commitment for the proof verification\n        bytes32 commitment = _createBatchCommitment(_newBatch, stateDiffHash);\n\n        return\n            StoredBatchInfo(\n                _newBatch.batchNumber,\n                _newBatch.newStateRoot,\n                _newBatch.indexRepeatedStorageChanges,\n                _newBatch.numberOfLayer1Txs,\n                _newBatch.priorityOperationsHash,\n                l2LogsTreeRoot,\n                _newBatch.timestamp,\n                commitment\n            );\n    }\n\n    /// @notice checks that the timestamps of both the new batch and the new L2 block are correct.\n    /// @param _packedBatchAndL2BlockTimestamp - packed batch and L2 block timestamp in a format of batchTimestamp * 2**128 + l2BatchTimestamp\n    /// @param _expectedBatchTimestamp - expected batch timestamp\n    /// @param _previousBatchTimestamp - the timestamp of the previous batch\n    function _verifyBatchTimestamp(\n        uint256 _packedBatchAndL2BlockTimestamp,\n        uint256 _expectedBatchTimestamp,\n        uint256 _previousBatchTimestamp\n    ) internal view {\n        // Check that the timestamp that came from the system context is expected\n        uint256 batchTimestamp = _packedBatchAndL2BlockTimestamp >> 128;\n        require(batchTimestamp == _expectedBatchTimestamp, \"tb\");\n\n        // While the fact that _previousBatchTimestamp < batchTimestamp is already checked on L2,\n        // we double check it here for clarity\n        require(_previousBatchTimestamp < batchTimestamp, \"h3\");\n\n        uint256 lastL2BlockTimestamp = _packedBatchAndL2BlockTimestamp & PACKED_L2_BLOCK_TIMESTAMP_MASK;\n\n        // All L2 blocks have timestamps within the range of [batchTimestamp, lastL2BatchTimestamp].\n        // So here we need to only double check that:\n        // - The timestamp of the batch is not too small.\n        // - The timestamp of the last L2 block is not too big.\n        require(block.timestamp - COMMIT_TIMESTAMP_NOT_OLDER <= batchTimestamp, \"h1\"); // New batch timestamp is too small\n        require(lastL2BlockTimestamp <= block.timestamp + COMMIT_TIMESTAMP_APPROXIMATION_DELTA, \"h2\"); // The last L2 block timestamp is too big\n    }\n\n    /// @dev Check that L2 logs are proper and batch contain all meta information for them\n    /// @dev The logs processed here should line up such that only one log for each key from the\n    ///      SystemLogKey enum in Constants.sol is processed per new batch.\n    /// @dev Data returned from here will be used to form the batch commitment.\n    function _processL2Logs(CommitBatchInfo calldata _newBatch, bytes32 _expectedSystemContractUpgradeTxHash)\n        internal\n        pure\n        returns (\n            uint256 numberOfLayer1Txs,\n            bytes32 chainedPriorityTxsHash,\n            bytes32 previousBatchHash,\n            bytes32 stateDiffHash,\n            bytes32 l2LogsTreeRoot,\n            uint256 packedBatchAndL2BlockTimestamp\n        )\n    {\n        // Copy L2 to L1 logs into memory.\n        bytes memory emittedL2Logs = _newBatch.systemLogs;\n\n        // Used as bitmap to set/check log processing happens exactly once.\n        // See SystemLogKey enum in Constants.sol for ordering.\n        uint256 processedLogs;\n\n        bytes32 providedL2ToL1PubdataHash = keccak256(_newBatch.totalL2ToL1Pubdata);\n\n        // linear traversal of the logs\n        for (uint256 i = 0; i < emittedL2Logs.length; i = i.uncheckedAdd(L2_TO_L1_LOG_SERIALIZE_SIZE)) {\n            // Extract the values to be compared to/used such as the log sender, key, and value\n            (address logSender, ) = UnsafeBytes.readAddress(emittedL2Logs, i + L2_LOG_ADDRESS_OFFSET);\n            (uint256 logKey, ) = UnsafeBytes.readUint256(emittedL2Logs, i + L2_LOG_KEY_OFFSET);\n            (bytes32 logValue, ) = UnsafeBytes.readBytes32(emittedL2Logs, i + L2_LOG_VALUE_OFFSET);\n\n            // Ensure that the log hasn't been processed already\n            require(!_checkBit(processedLogs, uint8(logKey)), \"kp\");\n            processedLogs = _setBit(processedLogs, uint8(logKey));\n\n            // Need to check that each log was sent by the correct address.\n            if (logKey == uint256(SystemLogKey.L2_TO_L1_LOGS_TREE_ROOT_KEY)) {\n                require(logSender == L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR, \"lm\");\n                l2LogsTreeRoot = logValue;\n            } else if (logKey == uint256(SystemLogKey.TOTAL_L2_TO_L1_PUBDATA_KEY)) {\n                require(logSender == L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR, \"ln\");\n                require(providedL2ToL1PubdataHash == logValue, \"wp\");\n            } else if (logKey == uint256(SystemLogKey.STATE_DIFF_HASH_KEY)) {\n                require(logSender == L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR, \"lb\");\n                stateDiffHash = logValue;\n            } else if (logKey == uint256(SystemLogKey.PACKED_BATCH_AND_L2_BLOCK_TIMESTAMP_KEY)) {\n                require(logSender == L2_SYSTEM_CONTEXT_SYSTEM_CONTRACT_ADDR, \"sc\");\n                packedBatchAndL2BlockTimestamp = uint256(logValue);\n            } else if (logKey == uint256(SystemLogKey.PREV_BATCH_HASH_KEY)) {\n                require(logSender == L2_SYSTEM_CONTEXT_SYSTEM_CONTRACT_ADDR, \"sv\");\n                previousBatchHash = logValue;\n            } else if (logKey == uint256(SystemLogKey.CHAINED_PRIORITY_TXN_HASH_KEY)) {\n                require(logSender == L2_BOOTLOADER_ADDRESS, \"bl\");\n                chainedPriorityTxsHash = logValue;\n            } else if (logKey == uint256(SystemLogKey.NUMBER_OF_LAYER_1_TXS_KEY)) {\n                require(logSender == L2_BOOTLOADER_ADDRESS, \"bk\");\n                numberOfLayer1Txs = uint256(logValue);\n            } else if (logKey == uint256(SystemLogKey.EXPECTED_SYSTEM_CONTRACT_UPGRADE_TX_HASH_KEY)) {\n                require(logSender == L2_BOOTLOADER_ADDRESS, \"bu\");\n                require(_expectedSystemContractUpgradeTxHash == logValue, \"ut\");\n            } else {\n                revert(\"ul\");\n            }\n        }\n\n        // We only require 7 logs to be checked, the 8th is if we are expecting a protocol upgrade\n        // Without the protocol upgrade we expect 7 logs: 2^7 - 1 = 127\n        // With the protocol upgrade we expect 8 logs: 2^8 - 1 = 255\n        if (_expectedSystemContractUpgradeTxHash == bytes32(0)) {\n            require(processedLogs == 127, \"b7\");\n        } else {\n            require(processedLogs == 255, \"b8\");\n        }\n    }\n\n    /// @notice Commit batch\n    /// @notice 1. Checks timestamp.\n    /// @notice 2. Process L2 logs.\n    /// @notice 3. Store batch commitments.\n    function commitBatches(StoredBatchInfo memory _lastCommittedBatchData, CommitBatchInfo[] calldata _newBatchesData)\n        external\n        override\n        nonReentrant\n        onlyValidator\n    {\n        // Check that we commit batches after last committed batch\n        require(s.storedBatchHashes[s.totalBatchesCommitted] == _hashStoredBatchInfo(_lastCommittedBatchData), \"i\"); // incorrect previous batch data\n        require(_newBatchesData.length > 0, \"No batches to commit\");\n\n        bytes32 systemContractsUpgradeTxHash = s.l2SystemContractsUpgradeTxHash;\n        // Upgrades are rarely done so we optimize a case with no active system contracts upgrade.\n        if (systemContractsUpgradeTxHash == bytes32(0) || s.l2SystemContractsUpgradeBatchNumber != 0) {\n            _commitBatchesWithoutSystemContractsUpgrade(_lastCommittedBatchData, _newBatchesData);\n        } else {\n            _commitBatchesWithSystemContractsUpgrade(\n                _lastCommittedBatchData,\n                _newBatchesData,\n                systemContractsUpgradeTxHash\n            );\n        }\n\n        s.totalBatchesCommitted = s.totalBatchesCommitted + _newBatchesData.length;\n    }\n\n    /// @dev Commits new batches without any system contracts upgrade.\n    /// @param _lastCommittedBatchData The data of the last committed batch.\n    /// @param _newBatchesData An array of batch data that needs to be committed.\n    function _commitBatchesWithoutSystemContractsUpgrade(\n        StoredBatchInfo memory _lastCommittedBatchData,\n        CommitBatchInfo[] calldata _newBatchesData\n    ) internal {\n        for (uint256 i = 0; i < _newBatchesData.length; i = i.uncheckedInc()) {\n            _lastCommittedBatchData = _commitOneBatch(_lastCommittedBatchData, _newBatchesData[i], bytes32(0));\n\n            s.storedBatchHashes[_lastCommittedBatchData.batchNumber] = _hashStoredBatchInfo(_lastCommittedBatchData);\n            emit BlockCommit(\n                _lastCommittedBatchData.batchNumber,\n                _lastCommittedBatchData.batchHash,\n                _lastCommittedBatchData.commitment\n            );\n        }\n    }\n\n    /// @dev Commits new batches with a system contracts upgrade transaction.\n    /// @param _lastCommittedBatchData The data of the last committed batch.\n    /// @param _newBatchesData An array of batch data that needs to be committed.\n    /// @param _systemContractUpgradeTxHash The transaction hash of the system contract upgrade.\n    function _commitBatchesWithSystemContractsUpgrade(\n        StoredBatchInfo memory _lastCommittedBatchData,\n        CommitBatchInfo[] calldata _newBatchesData,\n        bytes32 _systemContractUpgradeTxHash\n    ) internal {\n        // The system contract upgrade is designed to be executed atomically with the new bootloader, a default account,\n        // ZKP verifier, and other system parameters. Hence, we ensure that the upgrade transaction is\n        // carried out within the first batch committed after the upgrade.\n\n        // While the logic of the contract ensures that the s.l2SystemContractsUpgradeBatchNumber is 0 when this function is called,\n        // this check is added just in case. Since it is a hot read, it does not encure noticable gas cost.\n        require(s.l2SystemContractsUpgradeBatchNumber == 0, \"ik\");\n\n        // Save the batch number where the upgrade transaction was executed.\n        s.l2SystemContractsUpgradeBatchNumber = _newBatchesData[0].batchNumber;\n\n        for (uint256 i = 0; i < _newBatchesData.length; i = i.uncheckedInc()) {\n            // The upgrade transaction must only be included in the first batch.\n            bytes32 expectedUpgradeTxHash = i == 0 ? _systemContractUpgradeTxHash : bytes32(0);\n            _lastCommittedBatchData = _commitOneBatch(\n                _lastCommittedBatchData,\n                _newBatchesData[i],\n                expectedUpgradeTxHash\n            );\n\n            s.storedBatchHashes[_lastCommittedBatchData.batchNumber] = _hashStoredBatchInfo(_lastCommittedBatchData);\n            emit BlockCommit(\n                _lastCommittedBatchData.batchNumber,\n                _lastCommittedBatchData.batchHash,\n                _lastCommittedBatchData.commitment\n            );\n        }\n    }\n\n    /// @dev Pops the priority operations from the priority queue and returns a rolling hash of operations\n    function _collectOperationsFromPriorityQueue(uint256 _nPriorityOps) internal returns (bytes32 concatHash) {\n        concatHash = EMPTY_STRING_KECCAK;\n\n        for (uint256 i = 0; i < _nPriorityOps; i = i.uncheckedInc()) {\n            PriorityOperation memory priorityOp = s.priorityQueue.popFront();\n            concatHash = keccak256(abi.encode(concatHash, priorityOp.canonicalTxHash));\n        }\n    }\n\n    /// @dev Executes one batch\n    /// @dev 1. Processes all pending operations (Complete priority requests)\n    /// @dev 2. Finalizes batch on Ethereum\n    /// @dev _executedBatchIdx is an index in the array of the batches that we want to execute together\n    function _executeOneBatch(StoredBatchInfo memory _storedBatch, uint256 _executedBatchIdx) internal {\n        uint256 currentBatchNumber = _storedBatch.batchNumber;\n        require(currentBatchNumber == s.totalBatchesExecuted + _executedBatchIdx + 1, \"k\"); // Execute batches in order\n        require(\n            _hashStoredBatchInfo(_storedBatch) == s.storedBatchHashes[currentBatchNumber],\n            \"exe10\" // executing batch should be committed\n        );\n\n        bytes32 priorityOperationsHash = _collectOperationsFromPriorityQueue(_storedBatch.numberOfLayer1Txs);\n        require(priorityOperationsHash == _storedBatch.priorityOperationsHash, \"x\"); // priority operations hash does not match to expected\n\n        // Save root hash of L2 -> L1 logs tree\n        s.l2LogsRootHashes[currentBatchNumber] = _storedBatch.l2LogsTreeRoot;\n    }\n\n    /// @notice Execute batches, complete priority operations and process withdrawals.\n    /// @notice 1. Processes all pending operations (Complete priority requests)\n    /// @notice 2. Finalizes batch on Ethereum\n    function executeBatches(StoredBatchInfo[] calldata _batchesData) external nonReentrant onlyValidator {\n        uint256 nBatches = _batchesData.length;\n        for (uint256 i = 0; i < nBatches; i = i.uncheckedInc()) {\n            _executeOneBatch(_batchesData[i], i);\n            emit BlockExecution(_batchesData[i].batchNumber, _batchesData[i].batchHash, _batchesData[i].commitment);\n        }\n\n        uint256 newTotalBatchesExecuted = s.totalBatchesExecuted + nBatches;\n        s.totalBatchesExecuted = newTotalBatchesExecuted;\n        require(newTotalBatchesExecuted <= s.totalBatchesVerified, \"n\"); // Can't execute batches more than committed and proven currently.\n\n        uint256 batchWhenUpgradeHappened = s.l2SystemContractsUpgradeBatchNumber;\n        if (batchWhenUpgradeHappened != 0 && batchWhenUpgradeHappened <= newTotalBatchesExecuted) {\n            delete s.l2SystemContractsUpgradeTxHash;\n            delete s.l2SystemContra"
    }
  ]
}