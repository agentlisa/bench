{
  "Title": "[M-03] A cache that times out can be recovered",
  "Content": "\nRecover a cached value that has timed out, and a malicious user or contract can exploit this bug to fool other users or cause other unknown problems.\n\n### Proof of Concept\n\nThe `LocalCache#set_expire` function does not check whether the key has expired when setting a timeout:\n\n```rust\n    pub fn set_expire(&mut self, id: Cow<[u8]>, key: Cow<[u8]>, expire: u64) {\n        //@audit key values that have timed out may not be deleted\n        self.maybe_clear_expired();\n        if expire == 0 {\n            let _ = self.remove(id.as_ref(), key.as_ref());\n        } else if let Some(v) = self\n            .storages\n            .get_mut(id.as_ref())\n            .and_then(|storage| storage.kvs.get_mut(key.as_ref()))\n        {\n            //@audit You can increase the timeout period of a key value that has expired\n            v.expire_at = now().saturating_add(expire)\n        }\n    }\n    fn maybe_clear_expired(&mut self) {\n        self.sets_since_last_gc += 1;\n@>      if self.sets_since_last_gc == self.gc_interval {\n            self.clear_expired();\n        }\n    }\n```\n\nAs we can see from the above code, the `set_expire` function will first call `maybe_clear_expired`. The function `maybe_*` is called, so it won't necessarily delete keys that have expired. This function will not clean up expired keys until `gc count` reaches a certain value.\n\nTherefore, if there are keys that have expired, they are still queried from `storages` and then reset the expiration time. In other words, the `set_expire` function can cause an expired key to be reactivated.\n\nLet's look at another function, `LocalCache#get`:\n\n```rust\n    pub fn get(&self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        let entry = self.storages.get(id)?.kvs.get(key)?;\n@>      if entry.expire_at <= now() {\n            None\n        } else {\n            Some(entry.value.to_owned())\n        }\n    }\n```\n\nThe `get` function returns `None` if it finds that key has expired; this results in inconsistency of cached data.\n\nIn this way, when a key value (such as balance signature or debt) has expired, the attacker declares that the value no longer exists. The user is then asked to take some action, so the victim queries `LocalCache#get` and then finds that the value indeed no longer exists. The problem is that an attacker can use `set_expire` to restore this value.\n\nAnother attack scenario is:\n\nThe key value (such as an nft) that the developer thinks has expired no longer exists. However, a malicious user can make this value expire indefinitely if `set_expire` can be called.\n\nTips:\n\n`LocalCache#set` does not have this problem. `LocalCache#set` will call `Storage#set`, which will first call `self.remove` to remove the existing key.\n\n### Tools Used\n\nVS Code\n\n### Recommended Mitigation Steps\n\n```diff\n    pub fn set_expire(&mut self, id: Cow<[u8]>, key: Cow<[u8]>, expire: u64) {\n-       self.maybe_clear_expired();\n+       self.clear_expired();\n        if expire == 0 {\n            let _ = self.remove(id.as_ref(), key.as_ref());\n        } else if let Some(v) = self\n            .storages\n            .get_mut(id.as_ref())\n            .and_then(|storage| storage.kvs.get_mut(key.as_ref()))\n        {\n            v.expire_at = now().saturating_add(expire)\n        }\n    }\n```\n\n**[kvinwang (Phala) confirmed, but disagreed with severity and commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2019336011):**\n > This is a good catch.\n> \n> I'm not sure if this should be classified as `High Risk` level. The purpose of the local cache is to store volatile data, such as information fetched from an HTTP server. This data is expected to be lost at any time and may vary between different workers for the same contract. If the data is lost, the contract will re-fetch it from the external system.\n> \n> Therefore, I don't think it is suitable for storing on-chain assets that users can query.\n\n**[Lambda (judge) decreased severity to Medium and commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2023029935):**\n > Good finding, but agree that Medium is more appropriate, as the finding does not show any direct way how this can be used to steal funds, but only speculates about potential methods (which I am not sure if they can happen in practice and even if, they would have many assumptions).\n\n**[DadeKuma (warden) commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2025534255):**\n > I'm a bit skeptical about this finding. First of all, the docs state that the cache will store off-chain computations and not on-chain data that users can query/call:\n> \n> > //! The LocalCache provides a local KV cache for contracts to do some offchain computation.\n> > //! When we say local, it means that the data stored in the cache is different in different\n> > //! machines of the same contract. And the data might be lost when the runtime restart or caused\n> > //! by some kind of cache expiring mechanism.\n> \n> https://github.com/code-423n4/2024-03-phala-network/blob/a01ffbe992560d8d0f17deadfb9b9a2bed38377e/phala-blockchain/crates/pink/chain-extension/src/local_cache.rs#L1-L4\n> \n> There is no proof that these off-chain computations can be leveraged to impact the protocol or leak value in any way, especially because:\n> \n> 1. This data is expected to be lost at any time and can vary between different workers.\n> 2. These are off-chain computations which are not queriable by users.\n> \n> For these reasons, I believe this finding should be capped to QA/Low, not Medium risk.\n\n**[zhaojie (warden) commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2027002614):**\n > Although the user cannot query the cached data directly, the user can query it indirectly through the contract. The cache stores off-chain data, which can also cause problems if it is recovered.\n>\n> For example, price data -  the attacker lets the expired cache recover, there may be 2 different prices, which will lead to price manipulation. The report says that storing `xxxx` in the cache is just an assumption.\n> \n> Severity is determined by the judge, and I think it should at least remain Medium.\n\n**[DadeKuma (warden) commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2027052120):**\n > ~~The `set_expire` function is never called inside the audit [repository](https://github.com/search?q=repo%3Acode-423n4%2F2024-03-phala-network%20set_expire&type=code), nor in the main Phala [repository](https://github.com/search?q=repo%3APhala-Network%2Fphala-blockchain+set_expire&type=code), and~~ the only proof of how it will be used is inside the docs in the file itself, which points to off-chain computations.\n> \n> Using this cache to store on-chain data would be a misuse and a user error (and I don't think it would even make sense as the data is volatile/incongruent between the workers). This is also confirmed by the Sponsor in the comment above.\n> \n> Of course, the Judge will decide the final severity. I was just adding some details that might have been missed in the initial submission.\n> \n> **EDIT:** `set_expire` is actually called, GitHub search is broken; see comment below. My point on docs/normal usage stands.\n\n**[zhaojie (warden) commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2027067004):**\n > @DadeKuma - You should search for `set_expiration`.\n> \n> ```rust\n> pub fn set_expiration(contract: &[u8], key: &[u8], expiration: u64) {\n>     with_global_cache(|cache| cache.set_expire(contract.into(), key.into(), expiration))\n> }\n> ```\n> \n> https://github.com/code-423n4/2024-03-phala-network/blob/a01ffbe992560d8d0f17deadfb9b9a2bed38377e/phala-blockchain/crates/pink/chain-extension/src/local_cache.rs#L273\n\n**[Lambda (judge) commented](https://github.com/code-423n4/2024-03-phala-network-findings/issues/44#issuecomment-2028177501):**\n > > First of all, the docs state that the cache will store off-chain computations and not on-chain data that users can query/call:\n> \n> I agree with that. If it were used for on-chain data such as balances, High would be more appropriate. However, even for off-chain data, this behaviour could lead to problems. For instance, if the cache is used for caching some API/web responses (which seems to be one of the most common use cases for the cache), it is not unreasonable that a developer wants to have a maximum age of the response (and with `cache_set_expire`, there is an exposed function for exactly doing that, which does not always correctly as the warden has shown).\n>\n> In these cases, it also does not matter that the data is volatile/different between workers, because you care about the maximum age, but fetching newer data is fine. One example I can think of is betting on some result of an API service that refreshes daily where you would set the expiration such that no new requests are made until the next refresh. Of course, this has some assumptions, but I think they are pretty reasonable for such a runtime and it is well possible that there could be contracts that trigger this issue.\n\n***\n\n",
  "Impact": "MEDIUM",
  "Source": "https://code4rena.com/reports/2024-03-phala-network",
  "Code": [
    {
      "filename": "phala-blockchain/crates/pink/chain-extension/src/local_cache.rs",
      "content": "//! The LocalCache provides a local KV cache for contracts to do some offchain computation.\n//! When we say local, it means that the data stored in the cache is different in different\n//! machines of the same contract. And the data might loss when the pruntime restart or caused\n//! by some kind of cache expiring machanism.\n\nuse once_cell::sync::Lazy;\nuse pink::CacheOp;\nuse sp_core::{crypto::AccountId32, ByteArray};\nuse std::{\n    borrow::Cow,\n    collections::BTreeMap,\n    sync::atomic::{AtomicBool, Ordering},\n    time::Instant,\n};\n\npub use pink::chain_extension::StorageQuotaExceeded;\n\nstatic TEST_MODE: AtomicBool = AtomicBool::new(false);\n\npub(crate) fn enable_test_mode() {\n    TEST_MODE.store(true, Ordering::Relaxed);\n}\n\nfn with_global_cache<T>(f: impl FnOnce(&mut LocalCache) -> T) -> T {\n    if TEST_MODE.load(Ordering::Relaxed) {\n        // Unittests are running in multi-threaded env. Let's give per test case a cache instance.\n        use std::cell::RefCell;\n        thread_local! {\n            pub static GLOBAL_CACHE: RefCell<LocalCache> = RefCell::new(LocalCache::new());\n        }\n        GLOBAL_CACHE.with(move |cache| f(&mut cache.borrow_mut()))\n    } else {\n        use std::sync::Mutex;\n        pub static GLOBAL_CACHE: Mutex<LocalCache> = Mutex::new(LocalCache::new());\n        f(&mut GLOBAL_CACHE.lock().unwrap())\n    }\n}\n\nstruct Storage {\n    // Sum of the size of all the keys and values.\n    size: usize,\n    max_size: usize,\n    kvs: BTreeMap<Vec<u8>, StorageValue>,\n}\n\nimpl Storage {\n    fn new(max_size: usize) -> Self {\n        Self {\n            size: 0,\n            max_size,\n            kvs: Default::default(),\n        }\n    }\n\n    /// Runs garbage collection in cache to fit the max size\n    ///\n    /// Remove the items closest to the expiration date until the size can be fit into `max_size`.\n    fn fit_size(&mut self) {\n        if self.size <= self.max_size {\n            return;\n        }\n        let map = std::mem::take(&mut self.kvs);\n\n        let mut kvs: Vec<_> = map\n            .into_iter()\n            .map(|(k, v)| (v.expire_at, (k, v)))\n            .collect();\n        kvs.sort_by_key(|(expire, _)| *expire);\n        self.kvs = kvs\n            .into_iter()\n            .filter_map(|(_, (k, v))| {\n                if self.size <= self.max_size {\n                    return Some((k, v));\n                }\n                self.size -= k.len() + v.value.len();\n                None\n            })\n            .collect();\n    }\n\n    fn clear_expired(&mut self, now: u64) {\n        self.kvs.retain(|k, v| {\n            if v.expire_at > now {\n                true\n            } else {\n                self.size -= v.value.len() + k.len();\n                false\n            }\n        });\n    }\n\n    fn remove(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        let v = self.kvs.remove(key).map(|v| v.value);\n        if let Some(v) = &v {\n            self.size -= v.len() + key.len();\n        }\n        v\n    }\n\n    fn set(\n        &mut self,\n        key: Cow<[u8]>,\n        value: Cow<[u8]>,\n        lifetime: u64,\n    ) -> Result<(), StorageQuotaExceeded> {\n        _ = self.remove(key.as_ref());\n        let data_len = key.len() + value.len();\n        let mut store_size = self.size + data_len;\n        if store_size > self.max_size {\n            self.clear_expired(now());\n            store_size = self.size + data_len;\n            if store_size > self.max_size {\n                return Err(StorageQuotaExceeded);\n            }\n        }\n        self.size = store_size;\n        self.kvs.insert(\n            key.into_owned(),\n            StorageValue {\n                expire_at: now().saturating_add(lifetime),\n                value: value.into_owned(),\n            },\n        );\n        Ok(())\n    }\n\n    #[cfg(test)]\n    fn get(&self, key: &[u8]) -> Option<&StorageValue> {\n        self.kvs.get(key)\n    }\n}\n\nstruct StorageValue {\n    /// Expiration time in seconds since the first call to `now`.\n    expire_at: u64,\n    value: Vec<u8>,\n}\n\npub struct LocalCache {\n    /// Number of set ops between two GC ops.\n    gc_interval: u64,\n    /// Accumulated number of set ops since last GC.\n    sets_since_last_gc: u64,\n    /// Default expiration time in seconds.\n    default_value_lifetime: u64,\n    storages: BTreeMap<Vec<u8>, Storage>,\n}\n\nimpl LocalCache {\n    const fn new() -> Self {\n        Self {\n            gc_interval: 1000,\n            sets_since_last_gc: 0,\n            default_value_lifetime: 3600 * 24 * 7, // 1 week\n            storages: BTreeMap::new(),\n        }\n    }\n}\n\nimpl LocalCache {\n    fn maybe_clear_expired(&mut self) {\n        self.sets_since_last_gc += 1;\n        if self.sets_since_last_gc == self.gc_interval {\n            self.clear_expired();\n        }\n    }\n\n    fn clear_expired(&mut self) {\n        self.sets_since_last_gc = 0;\n        let now = now();\n        self.storages.values_mut().for_each(|storage| {\n            storage.clear_expired(now);\n        });\n    }\n\n    pub fn get(&self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        let entry = self.storages.get(id)?.kvs.get(key)?;\n        if entry.expire_at <= now() {\n            None\n        } else {\n            Some(entry.value.to_owned())\n        }\n    }\n\n    #[cfg(test)]\n    fn get_include_expired(&self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        Some(self.storages.get(id)?.kvs.get(key)?.value.to_owned())\n    }\n\n    pub fn set(\n        &mut self,\n        id: Cow<[u8]>,\n        key: Cow<[u8]>,\n        value: Cow<[u8]>,\n    ) -> Result<(), StorageQuotaExceeded> {\n        self.maybe_clear_expired();\n        self.storages\n            .get_mut(id.as_ref())\n            .ok_or(StorageQuotaExceeded)?\n            .set(key, value, self.default_value_lifetime)\n    }\n\n    pub fn set_expire(&mut self, id: Cow<[u8]>, key: Cow<[u8]>, expire: u64) {\n        self.maybe_clear_expired();\n        if expire == 0 {\n            let _ = self.remove(id.as_ref(), key.as_ref());\n        } else if let Some(v) = self\n            .storages\n            .get_mut(id.as_ref())\n            .and_then(|storage| storage.kvs.get_mut(key.as_ref()))\n        {\n            v.expire_at = now().saturating_add(expire)\n        }\n    }\n\n    pub fn remove(&mut self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        self.maybe_clear_expired();\n        let store = self.storages.get_mut(id)?;\n        store.remove(key)\n    }\n\n    pub fn apply_quotas<'a>(&mut self, quotas: impl IntoIterator<Item = (&'a [u8], usize)>) {\n        for (contract, max_size) in quotas.into_iter() {\n            log::trace!(\n                \"Applying cache quotas for {} max_size={max_size}\",\n                hex_fmt::HexFmt(contract)\n            );\n            if max_size == 0 {\n                self.storages.remove(contract);\n                continue;\n            }\n            match self.storages.get_mut(contract) {\n                Some(store) => {\n                    store.max_size = max_size;\n                    store.fit_size();\n                }\n                None => {\n                    self.storages\n                        .insert(contract.to_vec(), Storage::new(max_size));\n                }\n            }\n        }\n    }\n}\n\nfn now() -> u64 {\n    static REF_TIME: Lazy<Instant> = Lazy::new(Instant::now);\n    REF_TIME.elapsed().as_secs()\n}\n\npub fn apply_cache_op(contract: &AccountId32, op: CacheOp) {\n    match op {\n        CacheOp::Set { key, value } => {\n            let _ = set(contract.as_slice(), &key, &value);\n        }\n        CacheOp::SetExpiration { key, expiration } => {\n            set_expiration(contract.as_slice(), &key, expiration);\n        }\n        CacheOp::Remove { key } => {\n            let _ = remove(contract.as_slice(), &key);\n        }\n    }\n}\n\npub fn set(contract: &[u8], key: &[u8], value: &[u8]) -> Result<(), StorageQuotaExceeded> {\n    with_global_cache(|cache| cache.set(contract.into(), key.into(), value.into()))\n}\n\npub fn get(contract: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n    with_global_cache(|cache| cache.get(contract, key))\n}\n\npub fn set_expiration(contract: &[u8], key: &[u8], expiration: u64) {\n    with_global_cache(|cache| cache.set_expire(contract.into(), key.into(), expiration))\n}\n\npub fn remove(contract: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n    with_global_cache(|cache| cache.remove(contract, key))\n}\n\npub fn apply_quotas<'a>(quotas: impl IntoIterator<Item = (&'a [u8], usize)>) {\n    with_global_cache(|cache| cache.apply_quotas(quotas))\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    fn test_cache() -> LocalCache {\n        LocalCache {\n            gc_interval: 2,\n            sets_since_last_gc: 0,\n            default_value_lifetime: 2,\n            storages: Default::default(),\n        }\n    }\n\n    fn cow(s: &impl AsRef<[u8]>) -> Cow<[u8]> {\n        Cow::Borrowed(s.as_ref())\n    }\n\n    fn gc(cache: &mut LocalCache) {\n        for _ in 0..cache.gc_interval + 1 {\n            let _ = cache.set(cow(b\"_\"), cow(b\"_\"), cow(b\"_\"));\n        }\n    }\n\n    fn sleep(secs: u64) {\n        std::thread::sleep(std::time::Duration::from_secs(secs));\n    }\n\n    fn get_size(cache: &LocalCache, id: &[u8]) -> usize {\n        cache.storages.get(id).unwrap().size\n    }\n\n    #[test]\n    fn default_expire_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 1000)]);\n        let _ = cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\"));\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n\n        sleep(cache.default_value_lifetime);\n        assert_eq!(cache.get(b\"id\", b\"foo\"), None);\n        assert!(cache.get_include_expired(b\"id\", b\"foo\").is_some());\n        gc(&mut cache);\n        assert_eq!(cache.get_include_expired(b\"id\", b\"foo\"), None);\n        assert_eq!(get_size(&cache, b\"id\"), 0);\n    }\n\n    #[test]\n    fn set_expire_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 1000)]);\n\n        let _ = cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\"));\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n        cache.set_expire(cow(b\"id\"), cow(b\"foo\"), cache.default_value_lifetime + 2);\n\n        sleep(cache.default_value_lifetime);\n        gc(&mut cache);\n\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n\n        sleep(2);\n        gc(&mut cache);\n\n        assert_eq!(cache.get_include_expired(b\"id\", b\"foo\"), None);\n    }\n\n    #[test]\n    fn size_limit_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 10)]);\n\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\")).is_ok());\n        assert!(cache.set(cow(b\"id\"), cow(b\"bar\"), cow(b\"value\")).is_err());\n    }\n\n    #[test]\n    fn size_calc() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 100)]);\n\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"bar\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 6);\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"foobar\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 9);\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"foo\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 6);\n        assert!(cache.remove(b\"id\", b\"foo\").is_some());\n        assert_eq!(get_size(&cache, b\"id\"), 0);\n    }\n\n    #[test]\n    fn fit_size_works() {\n        let mut store = Storage::new(20);\n        assert!(store.set(cow(b\"k0\"), cow(b\"v0\"), 1000).is_ok());\n        assert_eq!(store.size, 4);\n        assert!(store.set(cow(b\"k1\"), cow(b\"v0\"), 50).is_ok());\n        assert_eq!(store.size, 8);\n        assert!(store.set(cow(b\"k2\"), cow(b\"v0\"), 200).is_ok());\n        assert_eq!(store.size, 12);\n        assert!(store.set(cow(b\"k3\"), cow(b\"v0\"), 100).is_ok());\n        assert_eq!(store.size, 16);\n        assert!(store.set(cow(b\"k4\"), cow(b\"v\"), 100).is_ok());\n        assert_eq!(store.size, 19);\n        assert!(store.set(cow(b\"k4\"), cow(b\"vvvvv\"), 100).is_err());\n        assert_eq!(store.size, 16);\n\n        assert!(store.get(b\"k0\").is_some());\n        assert!(store.get(b\"k1\").is_some());\n        assert!(store.get(b\"k2\").is_some());\n        assert!(store.get(b\"k3\").is_some());\n\n        store.max_size = 10;\n        store.fit_size();\n\n        assert!(store.get(b\"k0\").is_some());\n        assert!(store.get(b\"k2\").is_some());\n\n        assert!(store.get(b\"k1\").is_none());\n        assert!(store.get(b\"k3\").is_none());\n        assert_eq!(store.size, 8);\n    }\n\n    #[test]\n    fn cache_op_works() {\n        use pink::CacheOp;\n\n        enable_test_mode();\n\n        let key = b\"hello\";\n        let value = b\"world\";\n        let account = AccountId32::from([2u8; 32]);\n\n        apply_quotas([(account.as_slice(), 1024 * 1024 * 20), (&[1u8; 32], 0)]);\n\n        apply_cache_op(\n            &account,\n            CacheOp::Set {\n                key: key.to_vec(),\n                value: value.to_vec(),\n            },\n        );\n        let result = get(account.as_ref(), key);\n        assert_eq!(result.unwrap(), value);\n\n        apply_cache_op(&account, CacheOp::Remove { key: key.to_vec() });\n\n        let result = get(account.as_slice(), key);\n        assert!(result.is_none());\n\n        let result = set(account.as_slice(), key, value);\n        assert!(result.is_ok());\n        apply_cache_op(\n            &account,\n            CacheOp::SetExpiration {\n                key: key.to_vec(),\n                expiration: 0,\n            },\n        );\n        let result = get(account.as_slice(), key);\n        assert!(result.is_none());\n    }\n}"
    },
    {
      "filename": "phala-blockchain/crates/pink/chain-extension/src/local_cache.rs",
      "content": "//! The LocalCache provides a local KV cache for contracts to do some offchain computation.\n//! When we say local, it means that the data stored in the cache is different in different\n//! machines of the same contract. And the data might loss when the pruntime restart or caused\n//! by some kind of cache expiring machanism.\n\nuse once_cell::sync::Lazy;\nuse pink::CacheOp;\nuse sp_core::{crypto::AccountId32, ByteArray};\nuse std::{\n    borrow::Cow,\n    collections::BTreeMap,\n    sync::atomic::{AtomicBool, Ordering},\n    time::Instant,\n};\n\npub use pink::chain_extension::StorageQuotaExceeded;\n\nstatic TEST_MODE: AtomicBool = AtomicBool::new(false);\n\npub(crate) fn enable_test_mode() {\n    TEST_MODE.store(true, Ordering::Relaxed);\n}\n\nfn with_global_cache<T>(f: impl FnOnce(&mut LocalCache) -> T) -> T {\n    if TEST_MODE.load(Ordering::Relaxed) {\n        // Unittests are running in multi-threaded env. Let's give per test case a cache instance.\n        use std::cell::RefCell;\n        thread_local! {\n            pub static GLOBAL_CACHE: RefCell<LocalCache> = RefCell::new(LocalCache::new());\n        }\n        GLOBAL_CACHE.with(move |cache| f(&mut cache.borrow_mut()))\n    } else {\n        use std::sync::Mutex;\n        pub static GLOBAL_CACHE: Mutex<LocalCache> = Mutex::new(LocalCache::new());\n        f(&mut GLOBAL_CACHE.lock().unwrap())\n    }\n}\n\nstruct Storage {\n    // Sum of the size of all the keys and values.\n    size: usize,\n    max_size: usize,\n    kvs: BTreeMap<Vec<u8>, StorageValue>,\n}\n\nimpl Storage {\n    fn new(max_size: usize) -> Self {\n        Self {\n            size: 0,\n            max_size,\n            kvs: Default::default(),\n        }\n    }\n\n    /// Runs garbage collection in cache to fit the max size\n    ///\n    /// Remove the items closest to the expiration date until the size can be fit into `max_size`.\n    fn fit_size(&mut self) {\n        if self.size <= self.max_size {\n            return;\n        }\n        let map = std::mem::take(&mut self.kvs);\n\n        let mut kvs: Vec<_> = map\n            .into_iter()\n            .map(|(k, v)| (v.expire_at, (k, v)))\n            .collect();\n        kvs.sort_by_key(|(expire, _)| *expire);\n        self.kvs = kvs\n            .into_iter()\n            .filter_map(|(_, (k, v))| {\n                if self.size <= self.max_size {\n                    return Some((k, v));\n                }\n                self.size -= k.len() + v.value.len();\n                None\n            })\n            .collect();\n    }\n\n    fn clear_expired(&mut self, now: u64) {\n        self.kvs.retain(|k, v| {\n            if v.expire_at > now {\n                true\n            } else {\n                self.size -= v.value.len() + k.len();\n                false\n            }\n        });\n    }\n\n    fn remove(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        let v = self.kvs.remove(key).map(|v| v.value);\n        if let Some(v) = &v {\n            self.size -= v.len() + key.len();\n        }\n        v\n    }\n\n    fn set(\n        &mut self,\n        key: Cow<[u8]>,\n        value: Cow<[u8]>,\n        lifetime: u64,\n    ) -> Result<(), StorageQuotaExceeded> {\n        _ = self.remove(key.as_ref());\n        let data_len = key.len() + value.len();\n        let mut store_size = self.size + data_len;\n        if store_size > self.max_size {\n            self.clear_expired(now());\n            store_size = self.size + data_len;\n            if store_size > self.max_size {\n                return Err(StorageQuotaExceeded);\n            }\n        }\n        self.size = store_size;\n        self.kvs.insert(\n            key.into_owned(),\n            StorageValue {\n                expire_at: now().saturating_add(lifetime),\n                value: value.into_owned(),\n            },\n        );\n        Ok(())\n    }\n\n    #[cfg(test)]\n    fn get(&self, key: &[u8]) -> Option<&StorageValue> {\n        self.kvs.get(key)\n    }\n}\n\nstruct StorageValue {\n    /// Expiration time in seconds since the first call to `now`.\n    expire_at: u64,\n    value: Vec<u8>,\n}\n\npub struct LocalCache {\n    /// Number of set ops between two GC ops.\n    gc_interval: u64,\n    /// Accumulated number of set ops since last GC.\n    sets_since_last_gc: u64,\n    /// Default expiration time in seconds.\n    default_value_lifetime: u64,\n    storages: BTreeMap<Vec<u8>, Storage>,\n}\n\nimpl LocalCache {\n    const fn new() -> Self {\n        Self {\n            gc_interval: 1000,\n            sets_since_last_gc: 0,\n            default_value_lifetime: 3600 * 24 * 7, // 1 week\n            storages: BTreeMap::new(),\n        }\n    }\n}\n\nimpl LocalCache {\n    fn maybe_clear_expired(&mut self) {\n        self.sets_since_last_gc += 1;\n        if self.sets_since_last_gc == self.gc_interval {\n            self.clear_expired();\n        }\n    }\n\n    fn clear_expired(&mut self) {\n        self.sets_since_last_gc = 0;\n        let now = now();\n        self.storages.values_mut().for_each(|storage| {\n            storage.clear_expired(now);\n        });\n    }\n\n    pub fn get(&self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        let entry = self.storages.get(id)?.kvs.get(key)?;\n        if entry.expire_at <= now() {\n            None\n        } else {\n            Some(entry.value.to_owned())\n        }\n    }\n\n    #[cfg(test)]\n    fn get_include_expired(&self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        Some(self.storages.get(id)?.kvs.get(key)?.value.to_owned())\n    }\n\n    pub fn set(\n        &mut self,\n        id: Cow<[u8]>,\n        key: Cow<[u8]>,\n        value: Cow<[u8]>,\n    ) -> Result<(), StorageQuotaExceeded> {\n        self.maybe_clear_expired();\n        self.storages\n            .get_mut(id.as_ref())\n            .ok_or(StorageQuotaExceeded)?\n            .set(key, value, self.default_value_lifetime)\n    }\n\n    pub fn set_expire(&mut self, id: Cow<[u8]>, key: Cow<[u8]>, expire: u64) {\n        self.maybe_clear_expired();\n        if expire == 0 {\n            let _ = self.remove(id.as_ref(), key.as_ref());\n        } else if let Some(v) = self\n            .storages\n            .get_mut(id.as_ref())\n            .and_then(|storage| storage.kvs.get_mut(key.as_ref()))\n        {\n            v.expire_at = now().saturating_add(expire)\n        }\n    }\n\n    pub fn remove(&mut self, id: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n        self.maybe_clear_expired();\n        let store = self.storages.get_mut(id)?;\n        store.remove(key)\n    }\n\n    pub fn apply_quotas<'a>(&mut self, quotas: impl IntoIterator<Item = (&'a [u8], usize)>) {\n        for (contract, max_size) in quotas.into_iter() {\n            log::trace!(\n                \"Applying cache quotas for {} max_size={max_size}\",\n                hex_fmt::HexFmt(contract)\n            );\n            if max_size == 0 {\n                self.storages.remove(contract);\n                continue;\n            }\n            match self.storages.get_mut(contract) {\n                Some(store) => {\n                    store.max_size = max_size;\n                    store.fit_size();\n                }\n                None => {\n                    self.storages\n                        .insert(contract.to_vec(), Storage::new(max_size));\n                }\n            }\n        }\n    }\n}\n\nfn now() -> u64 {\n    static REF_TIME: Lazy<Instant> = Lazy::new(Instant::now);\n    REF_TIME.elapsed().as_secs()\n}\n\npub fn apply_cache_op(contract: &AccountId32, op: CacheOp) {\n    match op {\n        CacheOp::Set { key, value } => {\n            let _ = set(contract.as_slice(), &key, &value);\n        }\n        CacheOp::SetExpiration { key, expiration } => {\n            set_expiration(contract.as_slice(), &key, expiration);\n        }\n        CacheOp::Remove { key } => {\n            let _ = remove(contract.as_slice(), &key);\n        }\n    }\n}\n\npub fn set(contract: &[u8], key: &[u8], value: &[u8]) -> Result<(), StorageQuotaExceeded> {\n    with_global_cache(|cache| cache.set(contract.into(), key.into(), value.into()))\n}\n\npub fn get(contract: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n    with_global_cache(|cache| cache.get(contract, key))\n}\n\npub fn set_expiration(contract: &[u8], key: &[u8], expiration: u64) {\n    with_global_cache(|cache| cache.set_expire(contract.into(), key.into(), expiration))\n}\n\npub fn remove(contract: &[u8], key: &[u8]) -> Option<Vec<u8>> {\n    with_global_cache(|cache| cache.remove(contract, key))\n}\n\npub fn apply_quotas<'a>(quotas: impl IntoIterator<Item = (&'a [u8], usize)>) {\n    with_global_cache(|cache| cache.apply_quotas(quotas))\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    fn test_cache() -> LocalCache {\n        LocalCache {\n            gc_interval: 2,\n            sets_since_last_gc: 0,\n            default_value_lifetime: 2,\n            storages: Default::default(),\n        }\n    }\n\n    fn cow(s: &impl AsRef<[u8]>) -> Cow<[u8]> {\n        Cow::Borrowed(s.as_ref())\n    }\n\n    fn gc(cache: &mut LocalCache) {\n        for _ in 0..cache.gc_interval + 1 {\n            let _ = cache.set(cow(b\"_\"), cow(b\"_\"), cow(b\"_\"));\n        }\n    }\n\n    fn sleep(secs: u64) {\n        std::thread::sleep(std::time::Duration::from_secs(secs));\n    }\n\n    fn get_size(cache: &LocalCache, id: &[u8]) -> usize {\n        cache.storages.get(id).unwrap().size\n    }\n\n    #[test]\n    fn default_expire_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 1000)]);\n        let _ = cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\"));\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n\n        sleep(cache.default_value_lifetime);\n        assert_eq!(cache.get(b\"id\", b\"foo\"), None);\n        assert!(cache.get_include_expired(b\"id\", b\"foo\").is_some());\n        gc(&mut cache);\n        assert_eq!(cache.get_include_expired(b\"id\", b\"foo\"), None);\n        assert_eq!(get_size(&cache, b\"id\"), 0);\n    }\n\n    #[test]\n    fn set_expire_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 1000)]);\n\n        let _ = cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\"));\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n        cache.set_expire(cow(b\"id\"), cow(b\"foo\"), cache.default_value_lifetime + 2);\n\n        sleep(cache.default_value_lifetime);\n        gc(&mut cache);\n\n        assert_eq!(cache.get(b\"id\", b\"foo\"), Some(b\"value\".to_vec()));\n\n        sleep(2);\n        gc(&mut cache);\n\n        assert_eq!(cache.get_include_expired(b\"id\", b\"foo\"), None);\n    }\n\n    #[test]\n    fn size_limit_should_work() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 10)]);\n\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"value\")).is_ok());\n        assert!(cache.set(cow(b\"id\"), cow(b\"bar\"), cow(b\"value\")).is_err());\n    }\n\n    #[test]\n    fn size_calc() {\n        let mut cache = test_cache();\n        cache.apply_quotas([(&b\"id\"[..], 100)]);\n\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"bar\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 6);\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"foobar\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 9);\n        assert!(cache.set(cow(b\"id\"), cow(b\"foo\"), cow(b\"foo\")).is_ok());\n        assert_eq!(get_size(&cache, b\"id\"), 6);\n        assert!(cache.remove(b\"id\", b\"foo\").is_some());\n        assert_eq!(get_size(&cache, b\"id\"), 0);\n    }\n\n    #[test]\n    fn fit_size_works() {\n        let mut store = Storage::new(20);\n        assert!(store.set(cow(b\"k0\"), cow(b\"v0\"), 1000).is_ok());\n        assert_eq!(store.size, 4);\n        assert!(store.set(cow(b\"k1\"), cow(b\"v0\"), 50).is_ok());\n        assert_eq!(store.size, 8);\n        assert!(store.set(cow(b\"k2\"), cow(b\"v0\"), 200).is_ok());\n        assert_eq!(store.size, 12);\n        assert!(store.set(cow(b\"k3\"), cow(b\"v0\"), 100).is_ok());\n        assert_eq!(store.size, 16);\n        assert!(store.set(cow(b\"k4\"), cow(b\"v\"), 100).is_ok());\n        assert_eq!(store.size, 19);\n        assert!(store.set(cow(b\"k4\"), cow(b\"vvvvv\"), 100).is_err());\n        assert_eq!(store.size, 16);\n\n        assert!(store.get(b\"k0\").is_some());\n        assert!(store.get(b\"k1\").is_some());\n        assert!(store.get(b\"k2\").is_some());\n        assert!(store.get(b\"k3\").is_some());\n\n        store.max_size = 10;\n        store.fit_size();\n\n        assert!(store.get(b\"k0\").is_some());\n        assert!(store.get(b\"k2\").is_some());\n\n        assert!(store.get(b\"k1\").is_none());\n        assert!(store.get(b\"k3\").is_none());\n        assert_eq!(store.size, 8);\n    }\n\n    #[test]\n    fn cache_op_works() {\n        use pink::CacheOp;\n\n        enable_test_mode();\n\n        let key = b\"hello\";\n        let value = b\"world\";\n        let account = AccountId32::from([2u8; 32]);\n\n        apply_quotas([(account.as_slice(), 1024 * 1024 * 20), (&[1u8; 32], 0)]);\n\n        apply_cache_op(\n            &account,\n            CacheOp::Set {\n                key: key.to_vec(),\n                value: value.to_vec(),\n            },\n        );\n        let result = get(account.as_ref(), key);\n        assert_eq!(result.unwrap(), value);\n\n        apply_cache_op(&account, CacheOp::Remove { key: key.to_vec() });\n\n        let result = get(account.as_slice(), key);\n        assert!(result.is_none());\n\n        let result = set(account.as_slice(), key, value);\n        assert!(result.is_ok());\n        apply_cache_op(\n            &account,\n            CacheOp::SetExpiration {\n                key: key.to_vec(),\n                expiration: 0,\n            },\n        );\n        let result = get(account.as_slice(), key);\n        assert!(result.is_none());\n    }\n}"
    }
  ]
}