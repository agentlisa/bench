{
  "Title": "[20] Rogue validators can spam `revertBlocks` and make the chain unusable",
  "Content": "\nIn [Executor, function `revertBlocks`](https://github.com/matter-labs/era-contracts/blob/f06a58360a2b8e7129f64413998767ac169d1efd/ethereum/contracts/zksync/facets/Executor.sol#L440C1-L456C6) there is no way to prevent a rogue validator to spam this function and DOS other validators from executing the commited batches, as [executeBlocks](https://github.com/matter-labs/era-contracts/blob/f06a58360a2b8e7129f64413998767ac169d1efd/ethereum/contracts/zksync/facets/Executor.sol#L294C14-L294C27) has a delay enforced by [ValidatorTimelock](https://github.com/matter-labs/era-contracts/blob/f06a58360a2b8e7129f64413998767ac169d1efd/ethereum/contracts/zksync/ValidatorTimelock.sol#L109C1-L109C111), which is supposed to be non-zero. As the validator is currently controlled by Matter Labs, I'm putting it as a Low but consider implementing a delay or a slashing mechanism to validators that try to abuse their privileges by spamming `revertBlocks` for batches that do not benefit them, or even try to DOS the network.\n\n",
  "Impact": "LOW",
  "Source": "https://code4rena.com/reports/2023-10-zksync",
  "Code": [
    {
      "filename": "ethereum/contracts/zksync/facets/Executor.sol",
      "content": "// SPDX-License-Identifier: MIT\n\npragma solidity ^0.8.13;\n\nimport {Base} from \"./Base.sol\";\nimport {COMMIT_TIMESTAMP_NOT_OLDER, COMMIT_TIMESTAMP_APPROXIMATION_DELTA, EMPTY_STRING_KECCAK, L2_TO_L1_LOG_SERIALIZE_SIZE, INPUT_MASK, MAX_INITIAL_STORAGE_CHANGES_COMMITMENT_BYTES, MAX_REPEATED_STORAGE_CHANGES_COMMITMENT_BYTES, MAX_L2_TO_L1_LOGS_COMMITMENT_BYTES, PACKED_L2_BLOCK_TIMESTAMP_MASK} from \"../Config.sol\";\nimport {IExecutor} from \"../interfaces/IExecutor.sol\";\nimport {PairingsBn254} from \"../libraries/PairingsBn254.sol\";\nimport {PriorityQueue, PriorityOperation} from \"../libraries/PriorityQueue.sol\";\nimport {UncheckedMath} from \"../../common/libraries/UncheckedMath.sol\";\nimport {UnsafeBytes} from \"../../common/libraries/UnsafeBytes.sol\";\nimport {L2ContractHelper} from \"../../common/libraries/L2ContractHelper.sol\";\nimport {VerifierParams} from \"../Storage.sol\";\nimport {L2_BOOTLOADER_ADDRESS, L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR, L2_SYSTEM_CONTEXT_SYSTEM_CONTRACT_ADDR, L2_KNOWN_CODE_STORAGE_SYSTEM_CONTRACT_ADDR} from \"../../common/L2ContractAddresses.sol\";\n\n/// @title zkSync Executor contract capable of processing events emitted in the zkSync protocol.\n/// @author Matter Labs\ncontract ExecutorFacet is Base, IExecutor {\n    using UncheckedMath for uint256;\n    using PriorityQueue for PriorityQueue.Queue;\n\n    string public constant override getName = \"ExecutorFacet\";\n\n    /// @dev Process one block commit using the previous block StoredBlockInfo\n    /// @dev returns new block StoredBlockInfo\n    /// @notice Does not change storage\n    function _commitOneBlock(\n        StoredBlockInfo memory _previousBlock,\n        CommitBlockInfo calldata _newBlock,\n        bytes32 _expectedSystemContractUpgradeTxHash\n    ) internal view returns (StoredBlockInfo memory) {\n        require(_newBlock.blockNumber == _previousBlock.blockNumber + 1, \"f\"); // only commit next block\n\n        // Check that block contain all meta information for L2 logs.\n        // Get the chained hash of priority transaction hashes.\n        (\n            uint256 expectedNumberOfLayer1Txs,\n            bytes32 expectedPriorityOperationsHash,\n            bytes32 previousBlockHash,\n            uint256 packedBatchAndL2BlockTimestamp\n        ) = _processL2Logs(_newBlock, _expectedSystemContractUpgradeTxHash);\n\n        require(_previousBlock.blockHash == previousBlockHash, \"l\");\n        // Check that the priority operation hash in the L2 logs is as expected\n        require(expectedPriorityOperationsHash == _newBlock.priorityOperationsHash, \"t\");\n        // Check that the number of processed priority operations is as expected\n        require(expectedNumberOfLayer1Txs == _newBlock.numberOfLayer1Txs, \"ta\");\n\n        // Check the timestamp of the new block\n        _verifyBlockTimestamp(packedBatchAndL2BlockTimestamp, _newBlock.timestamp, _previousBlock.timestamp);\n\n        // Preventing \"stack too deep error\"\n        {\n            // Check the index of repeated storage writes\n            uint256 newStorageChangesIndexes = uint256(uint32(bytes4(_newBlock.initialStorageChanges[:4])));\n            require(\n                _previousBlock.indexRepeatedStorageChanges + newStorageChangesIndexes ==\n                    _newBlock.indexRepeatedStorageChanges,\n                \"yq\"\n            );\n        }\n\n        // Create block commitment for the proof verification\n        bytes32 commitment = _createBlockCommitment(_newBlock);\n\n        return\n            StoredBlockInfo(\n                _newBlock.blockNumber,\n                _newBlock.newStateRoot,\n                _newBlock.indexRepeatedStorageChanges,\n                _newBlock.numberOfLayer1Txs,\n                _newBlock.priorityOperationsHash,\n                _newBlock.l2LogsTreeRoot,\n                _newBlock.timestamp,\n                commitment\n            );\n    }\n\n    /// @notice checks that the timestamps of both the new batch and the new L2 block are correct.\n    /// @param _packedBatchAndL2BlockTimestamp - packed batch and L2 block timestamp in a foramt of batchTimestamp * 2**128 + l2BlockTimestamp\n    /// @param _expectedBatchTimestamp - expected batch timestamp\n    /// @param _previousBatchTimestamp - the timestamp of the previous batch\n    function _verifyBlockTimestamp(\n        uint256 _packedBatchAndL2BlockTimestamp,\n        uint256 _expectedBatchTimestamp,\n        uint256 _previousBatchTimestamp\n    ) internal view {\n        // Check that the timestamp that came from the system context is expected\n        uint256 batchTimestamp = _packedBatchAndL2BlockTimestamp >> 128;\n        require(batchTimestamp == _expectedBatchTimestamp, \"tb\");\n\n        // While the fact that _previousBatchTimestamp < batchTimestamp is already checked on L2,\n        // we double check it here for clarity\n        require(_previousBatchTimestamp < batchTimestamp, \"h\");\n\n        uint256 lastL2BlockTimestamp = _packedBatchAndL2BlockTimestamp & PACKED_L2_BLOCK_TIMESTAMP_MASK;\n\n        // On L2, all blocks have timestamps within the range of [batchTimestamp, lastL2BlockTimestamp].\n        // So here we need to only double check that:\n        // - The timestamp of the batch is not too small.\n        // - The timestamp of the last L2 block is not too big.\n        require(block.timestamp - COMMIT_TIMESTAMP_NOT_OLDER <= batchTimestamp, \"h1\"); // New batch timestamp is too small\n        require(lastL2BlockTimestamp <= block.timestamp + COMMIT_TIMESTAMP_APPROXIMATION_DELTA, \"h2\"); // The last L2 block timestamp is too big\n    }\n\n    /// @dev Check that L2 logs are proper and block contain all meta information for them\n    function _processL2Logs(CommitBlockInfo calldata _newBlock, bytes32 _expectedSystemContractUpgradeTxHash)\n        internal\n        pure\n        returns (\n            uint256 numberOfLayer1Txs,\n            bytes32 chainedPriorityTxsHash,\n            bytes32 previousBlockHash,\n            uint256 packedBatchAndL2BlockTimestamp\n        )\n    {\n        // Copy L2 to L1 logs into memory.\n        bytes memory emittedL2Logs = _newBlock.l2Logs[4:];\n        uint256 currentMessage;\n        // Auxiliary variable that is needed to enforce that `previousBlockHash` and `blockTimestamp` was read exactly one time\n        bool isSystemContextLogProcessed;\n        bytes[] calldata factoryDeps = _newBlock.factoryDeps;\n        uint256 currentBytecode;\n\n        chainedPriorityTxsHash = EMPTY_STRING_KECCAK;\n\n        // linear traversal of the logs\n        for (uint256 i = 0; i < emittedL2Logs.length; i = i.uncheckedAdd(L2_TO_L1_LOG_SERIALIZE_SIZE)) {\n            (address logSender, ) = UnsafeBytes.readAddress(emittedL2Logs, i + 4);\n\n            // show preimage for hashed message stored in log\n            if (logSender == L2_TO_L1_MESSENGER_SYSTEM_CONTRACT_ADDR) {\n                (bytes32 hashedMessage, ) = UnsafeBytes.readBytes32(emittedL2Logs, i + 56);\n                require(keccak256(_newBlock.l2ArbitraryLengthMessages[currentMessage]) == hashedMessage, \"k2\");\n\n                currentMessage = currentMessage.uncheckedInc();\n            } else if (logSender == L2_BOOTLOADER_ADDRESS) {\n                (bytes32 canonicalTxHash, ) = UnsafeBytes.readBytes32(emittedL2Logs, i + 24);\n\n                if (_expectedSystemContractUpgradeTxHash != bytes32(0)) {\n                    require(_expectedSystemContractUpgradeTxHash == canonicalTxHash, \"bz\");\n                    _expectedSystemContractUpgradeTxHash = bytes32(0);\n                } else {\n                    chainedPriorityTxsHash = keccak256(abi.encode(chainedPriorityTxsHash, canonicalTxHash));\n                    // Overflow is not realistic\n                    numberOfLayer1Txs = numberOfLayer1Txs.uncheckedInc();\n                }\n            } else if (logSender == L2_SYSTEM_CONTEXT_SYSTEM_CONTRACT_ADDR) {\n                // Make sure that the system context log wasn't processed yet, to\n                // avoid accident double reading `blockTimestamp` and `previousBlockHash`\n                require(!isSystemContextLogProcessed, \"fx\");\n                (packedBatchAndL2BlockTimestamp, ) = UnsafeBytes.readUint256(emittedL2Logs, i + 24);\n                (previousBlockHash, ) = UnsafeBytes.readBytes32(emittedL2Logs, i + 56);\n                // Mark system context log as processed\n                isSystemContextLogProcessed = true;\n            } else if (logSender == L2_KNOWN_CODE_STORAGE_SYSTEM_CONTRACT_ADDR) {\n                (bytes32 bytecodeHash, ) = UnsafeBytes.readBytes32(emittedL2Logs, i + 24);\n                require(bytecodeHash == L2ContractHelper.hashL2Bytecode(factoryDeps[currentBytecode]), \"k3\");\n\n                currentBytecode = currentBytecode.uncheckedInc();\n            } else {\n                // Only some system contracts could send raw logs from L2 to L1, double check that invariant holds here.\n                revert(\"ne\");\n            }\n        }\n        // To check that only relevant preimages have been included in the calldata\n        require(currentBytecode == factoryDeps.length, \"ym\");\n        require(currentMessage == _newBlock.l2ArbitraryLengthMessages.length, \"pl\");\n        // `blockTimestamp` and `previousBlockHash` wasn't read from L2 logs\n        require(isSystemContextLogProcessed, \"by\");\n\n        // Making sure that the system contract upgrade was included if needed\n        require(_expectedSystemContractUpgradeTxHash == bytes32(0), \"bw\");\n    }\n\n    /// @notice Commit block\n    /// @notice 1. Checks timestamp.\n    /// @notice 2. Process L2 logs.\n    /// @notice 3. Store block commitments.\n    function commitBlocks(StoredBlockInfo memory _lastCommittedBlockData, CommitBlockInfo[] calldata _newBlocksData)\n        external\n        override\n        nonReentrant\n        onlyValidator\n    {\n        // Check that we commit blocks after last committed block\n        require(s.storedBlockHashes[s.totalBlocksCommitted] == _hashStoredBlockInfo(_lastCommittedBlockData), \"i\"); // incorrect previous block data\n        require(_newBlocksData.length > 0, \"No blocks to commit\");\n\n        bytes32 systemContractsUpgradeTxHash = s.l2SystemContractsUpgradeTxHash;\n        // Upgrades are rarely done so we optimize a case with no active system contracts upgrade.\n        if (systemContractsUpgradeTxHash == bytes32(0) || s.l2SystemContractsUpgradeBlockNumber != 0) {\n            _commitBlocksWithoutSystemContractsUpgrade(_lastCommittedBlockData, _newBlocksData);\n        } else {\n            _commitBlocksWithSystemContractsUpgrade(\n                _lastCommittedBlockData,\n                _newBlocksData,\n                systemContractsUpgradeTxHash\n            );\n        }\n\n        s.totalBlocksCommitted = s.totalBlocksCommitted + _newBlocksData.length;\n    }\n\n    /// @dev Commits new blocks without any system contracts upgrade.\n    /// @param _lastCommittedBlockData The data of the last committed block.\n    /// @param _newBlocksData An array of block data that needs to be committed.\n    function _commitBlocksWithoutSystemContractsUpgrade(\n        StoredBlockInfo memory _lastCommittedBlockData,\n        CommitBlockInfo[] calldata _newBlocksData\n    ) internal {\n        for (uint256 i = 0; i < _newBlocksData.length; i = i.uncheckedInc()) {\n            _lastCommittedBlockData = _commitOneBlock(_lastCommittedBlockData, _newBlocksData[i], bytes32(0));\n\n            s.storedBlockHashes[_lastCommittedBlockData.blockNumber] = _hashStoredBlockInfo(_lastCommittedBlockData);\n            emit BlockCommit(\n                _lastCommittedBlockData.blockNumber,\n                _lastCommittedBlockData.blockHash,\n                _lastCommittedBlockData.commitment\n            );\n        }\n    }\n\n    /// @dev Commits new blocks with a system contracts upgrade transaction.\n    /// @param _lastCommittedBlockData The data of the last committed block.\n    /// @param _newBlocksData An array of block data that needs to be committed.\n    /// @param _systemContractUpgradeTxHash The transaction hash of the system contract upgrade.\n    function _commitBlocksWithSystemContractsUpgrade(\n        StoredBlockInfo memory _lastCommittedBlockData,\n        CommitBlockInfo[] calldata _newBlocksData,\n        bytes32 _systemContractUpgradeTxHash\n    ) internal {\n        // The system contract upgrade is designed to be executed atomically with the new bootloader, a default account,\n        // ZKP verifier, and other system parameters. Hence, we ensure that the upgrade transaction is\n        // carried out within the first block committed after the upgrade.\n\n        // While the logic of the contract ensures that the s.l2SystemContractsUpgradeBlockNumber is 0 when this function is called,\n        // this check is added just in case. Since it is a hot read, it does not encure noticable gas cost.\n        require(s.l2SystemContractsUpgradeBlockNumber == 0, \"ik\");\n\n        // Save the block number where the upgrade transaction was executed.\n        s.l2SystemContractsUpgradeBlockNumber = _newBlocksData[0].blockNumber;\n\n        for (uint256 i = 0; i < _newBlocksData.length; i = i.uncheckedInc()) {\n            // The upgrade transaction must only be included in the first block.\n            bytes32 expectedUpgradeTxHash = i == 0 ? _systemContractUpgradeTxHash : bytes32(0);\n            _lastCommittedBlockData = _commitOneBlock(\n                _lastCommittedBlockData,\n                _newBlocksData[i],\n                expectedUpgradeTxHash\n            );\n\n            s.storedBlockHashes[_lastCommittedBlockData.blockNumber] = _hashStoredBlockInfo(_lastCommittedBlockData);\n            emit BlockCommit(\n                _lastCommittedBlockData.blockNumber,\n                _lastCommittedBlockData.blockHash,\n                _lastCommittedBlockData.commitment\n            );\n        }\n    }\n\n    /// @dev Pops the priority operations from the priority queue and returns a rolling hash of operations\n    function _collectOperationsFromPriorityQueue(uint256 _nPriorityOps) internal returns (bytes32 concatHash) {\n        concatHash = EMPTY_STRING_KECCAK;\n\n        for (uint256 i = 0; i < _nPriorityOps; i = i.uncheckedInc()) {\n            PriorityOperation memory priorityOp = s.priorityQueue.popFront();\n            concatHash = keccak256(abi.encode(concatHash, priorityOp.canonicalTxHash));\n        }\n    }\n\n    /// @dev Executes one block\n    /// @dev 1. Processes all pending operations (Complete priority requests)\n    /// @dev 2. Finalizes block on Ethereum\n    /// @dev _executedBlockIdx is an index in the array of the blocks that we want to execute together\n    function _executeOneBlock(StoredBlockInfo memory _storedBlock, uint256 _executedBlockIdx) internal {\n        uint256 currentBlockNumber = _storedBlock.blockNumber;\n        require(currentBlockNumber == s.totalBlocksExecuted + _executedBlockIdx + 1, \"k\"); // Execute blocks in order\n        require(\n            _hashStoredBlockInfo(_storedBlock) == s.storedBlockHashes[currentBlockNumber],\n            \"exe10\" // executing block should be committed\n        );\n\n        bytes32 priorityOperationsHash = _collectOperationsFromPriorityQueue(_storedBlock.numberOfLayer1Txs);\n        require(priorityOperationsHash == _storedBlock.priorityOperationsHash, \"x\"); // priority operations hash does not match to expected\n\n        // Save root hash of L2 -> L1 logs tree\n        s.l2LogsRootHashes[currentBlockNumber] = _storedBlock.l2LogsTreeRoot;\n    }\n\n    /// @notice Execute blocks, complete priority operations and process withdrawals.\n    /// @notice 1. Processes all pending operations (Complete priority requests)\n    /// @notice 2. Finalizes block on Ethereum\n    function executeBlocks(StoredBlockInfo[] calldata _blocksData) external nonReentrant onlyValidator {\n        uint256 nBlocks = _blocksData.length;\n        for (uint256 i = 0; i < nBlocks; i = i.uncheckedInc()) {\n            _executeOneBlock(_blocksData[i], i);\n            emit BlockExecution(_blocksData[i].blockNumber, _blocksData[i].blockHash, _blocksData[i].commitment);\n        }\n\n        uint256 newTotalBlocksExecuted = s.totalBlocksExecuted + nBlocks;\n        s.totalBlocksExecuted = newTotalBlocksExecuted;\n        require(newTotalBlocksExecuted <= s.totalBlocksVerified, \"n\"); // Can't execute blocks more than committed and proven currently.\n\n        uint256 blockWhenUpgradeHappened = s.l2SystemContractsUpgradeBlockNumber;\n        if (blockWhenUpgradeHappened != 0 && blockWhenUpgradeHappened <= newTotalBlocksExecuted) {\n            delete s.l2SystemContractsUpgradeTxHash;\n            delete s.l2SystemContractsUpgradeBlockNumber;\n        }\n    }\n\n    /// @notice Blocks commitment verification.\n    /// @notice Only verifies block commitments without any other processing\n    function proveBlocks(\n        StoredBlockInfo calldata _prevBlock,\n        StoredBlockInfo[] calldata _committedBlocks,\n        ProofInput calldata _proof\n    ) external nonReentrant onlyValidator {\n        // Save the variables into the stack to save gas on reading them later\n        uint256 currentTotalBlocksVerified = s.totalBlocksVerified;\n        uint256 committedBlocksLength = _committedBlocks.length;\n\n        // Save the variable from the storage to memory to save gas\n        VerifierParams memory verifierParams = s.verifierParams;\n\n        // Initialize the array, that will be used as public input to the ZKP\n        uint256[] memory proofPublicInput = new uint256[](committedBlocksLength);\n\n        // Check that the block passed by the validator is indeed the first unverified block\n        require(_hashStoredBlockInfo(_prevBlock) == s.storedBlockHashes[currentTotalBlocksVerified], \"t1\");\n\n        bytes32 prevBlockCommitment = _prevBlock.commitment;\n        for (uint256 i = 0; i < committedBlocksLength; i = i.uncheckedInc()) {\n            currentTotalBlocksVerified = currentTotalBlocksVerified.uncheckedInc();\n            require(_hashStoredBlockInfo(_committedBlocks[i]) == s.storedBlockHashes[currentTotalBlocksVerified], \"o1\");\n\n            bytes32 currentBlockCommitment = _committedBlocks[i].commitment;\n            proofPublicInput[i] = _getBlockProofPublicInput(\n                prevBlockCommitment,\n                currentBlockCommitment,\n                _proof,\n                verifierParams\n            );\n\n            prevBlockCommitment = currentBlockCommitment;\n        }\n        require(currentTotalBlocksVerified <= s.totalBlocksCommitted, \"q\");\n\n        // #if DUMMY_VERIFIER\n\n        // Additional level of protection for the mainnet\n        assert(block.chainid != 1);\n        // We allow skipping the zkp verification for the test(net) environment\n        // If the proof is not empty, verify it, otherwise, skip the verification\n        if (_proof.serializedProof.length > 0) {\n            // TODO: We keep the code duplication here to NOT to invalidate the audit, refactor it before the next audit. (SMA-1631)\n            bool successVerifyProof = s.verifier.verify_serialized_proof(proofPublicInput, _proof.serializedProof);\n            require(successVerifyProof, \"p\"); // Proof verification fail\n\n            // Verify the recursive part that was given to us through the public input\n            bool successProofAggregation = _verifyRecursivePartOfProof(_proof.recursiveAggregationInput);\n            require(successProofAggregation, \"hh\"); // Proof aggregation must be valid\n        }\n        // #else\n        bool successVerifyProof = s.verifier.verify_serialized_proof(proofPublicInput, _proof.serializedProof);\n        require(successVerifyProof, \"p\"); // Proof verification fail\n\n        // Verify the recursive part that was given to us through the public input\n        bool successProofAggregation = _verifyRecursivePartOfProof(_proof.recursiveAggregationInput);\n        require(successProofAggregation, \"hh\"); // Proof aggregation must be valid\n        // #endif\n\n        emit BlocksVerification(s.totalBlocksVerified, currentTotalBlocksVerified);\n        s.totalBlocksVerified = currentTotalBlocksVerified;\n    }\n\n    /// @dev Gets zk proof public input\n    function _getBlockProofPublicInput(\n        bytes32 _prevBlockCommitment,\n        bytes32 _currentBlockCommitment,\n        ProofInput calldata _proof,\n        VerifierParams memory _verifierParams\n    ) internal pure returns (uint256) {\n        return\n            uint256(\n                keccak256(\n                    abi.encodePacked(\n                        _prevBlockCommitment,\n                        _currentBlockCommitment,\n                        _verifierParams.recursionNodeLevelVkHash,\n                        _verifierParams.recursionLeafLevelVkHash,\n                        _verifierParams.recursionCircuitsSetVksHash,\n                        _proof.recursiveAggregationInput\n                    )\n                )\n            ) & INPUT_MASK;\n    }\n\n    /// @dev Verify a part of the zkp, that is responsible for the aggregation\n    function _verifyRecursivePartOfProof(uint256[] calldata _recursiveAggregationInput) internal view returns (bool) {\n        require(_recursiveAggregationInput.length == 4, \"vr\");\n\n        PairingsBn254.G1Point memory pairWithGen = PairingsBn254.new_g1_checked(\n            _recursiveAggregationInput[0],\n            _recursiveAggregationInput[1]\n        );\n        PairingsBn254.G1Point memory pairWithX = PairingsBn254.new_g1_checked(\n            _recursiveAggregationInput[2],\n            _recursiveAggregationInput[3]\n        );\n\n        PairingsBn254.G2Point memory g2Gen = PairingsBn254.new_g2(\n            [\n                0x198e9393920d483a7260bfb731fb5d25f1aa493335a9e71297e485b7aef312c2,\n                0x1800deef121f1e76426a00665e5c4479674322d4f75edadd46debd5cd992f6ed\n            ],\n            [\n                0x090689d0585ff075ec9e99ad690c3395bc4b313370b38ef355acdadcd122975b,\n                0x12c85ea5db8c6deb4aab71808dcb408fe3d1e7690c43d37b4ce6cc0166fa7daa\n            ]\n        );\n        PairingsBn254.G2Point memory g2X = PairingsBn254.new_g2(\n            [\n                0x260e01b251f6f1c7e7ff4e580791dee8ea51d87a358e038b4efe30fac09383c1,\n                0x0118c4d5b837bcc2bc89b5b398b5974e9f5944073b32078b7e231fec938883b0\n            ],\n            [\n                0x04fc6369f7110fe3d25156c1bb9a72859cf2a04641f99ba4ee413c80da6a5fe4,\n                0x22febda3c0c0632a56475b4214e5615e11e6dd3f96e6cea2854a87d4dacc5e55\n            ]\n        );\n\n        return PairingsBn254.pairingProd2(pairWithGen, g2Gen, pairWithX, g2X);\n    }\n\n    /// @notice Reverts unexecuted blocks\n    /// @param _newLastBlock block number after which blocks should be reverted\n    /// NOTE: Doesn't delete the stored data about blocks, but only decreases\n    /// counters that are responsible for the number of blocks\n    function revertBlocks(uint256 _newLastBlock) external nonReentrant onlyValidator {\n        require(s.totalBlocksCommitted > _newLastBlock, \"v1\"); // The last committed block is less than new last block\n        uint256 newTotalBlocksCommitted = _maxU256(_newLastBlock, s.totalBlocksExecuted);\n\n        if (newTotalBlocksCommitted < s.totalBlocksVerified) {\n            s.totalBlocksVerified = newTotalBlocksCommitted;\n        }\n        s.totalBlocksCommitted = newTotalBlocksCommitted;\n\n        // Reset the block number of the executed system contracts upgrade transaction if the block\n        // where the system contracts upgrade was committed is among the reverted blocks.\n        if (s.l2SystemContractsUpgradeBlockNumber > newTotalBlocksCommitted) {\n            delete s.l2SystemContractsUpgradeBlockNumber;\n        }\n\n        emit BlocksRevert(s.totalBlocksCommitted, s.totalBlocksVerified, s.totalBlocksExecuted);\n    }\n\n    /// @notice Returns larger of two values\n    function _maxU256(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a < b ? b : a;\n    }\n\n    /// @dev Creates block commitment from its data\n    function _createBlockCommitment(CommitBlockInfo calldata _newBlockData) internal view returns (bytes32) {\n        bytes32 passThroughDataHash = keccak256(_blockPassThroughData(_newBlockData));\n        bytes32 metadataHash = keccak256(_blockMetaParameters());\n        bytes32 auxiliaryOutputHash = keccak256(_blockAuxiliaryOutput(_newBlockData));\n\n        return keccak256(abi.encode(passThroughDataHash, metadataHash, auxiliaryOutputHash));\n    }\n\n    function _blockPassThroughData(CommitBlockInfo calldata _block) internal pure returns (bytes memory) {\n        return\n            abi.encodePacked(\n                _block.indexRepeatedStorageChanges,\n                _block.newStateRoot,\n                uint64(0), // index repeated storage changes in zkPorter\n                bytes32(0) // zkPorter block hash\n            );\n    }\n\n    function _blockMetaParameters() internal view returns (bytes memory) {\n        return abi.encodePacked(s.zkPorterIsAvailable, s.l2BootloaderBytecodeHash, s.l2DefaultAccountBytecodeHash);\n    }\n\n    function _blockAuxiliaryOutput(CommitBlockInfo calldata _block) internal pure returns (bytes memory) {\n        require(_block.initialStorageChanges.length <= MAX_INITIAL_STORAGE_CHANGES_COMMITMENT_BYTES, \"pf\");\n        require(_block.repeatedStorageChanges.length <= MAX_REPEATED_STORAGE_CHANGES_COMMITMENT_BYTES, \"py\");\n        require(_block.l2Logs.length <= MAX_L2_TO_L1_LOGS_COMMITMENT_BYTES, \"pu\");\n\n        bytes32 initialStorageChangesHash = keccak256(_block.initialStorageChanges);\n        bytes32 repeatedStorageChangesHash = keccak256(_block.repeatedStorageChanges);\n        bytes32 l2ToL1LogsHash = keccak256(_block.l2Logs);\n\n        return abi.encode(_block.l2LogsTreeRoot, l2ToL1LogsHash, initialStorageChangesHash, repeatedStorageChangesHash);\n    }\n\n    /// @notice Returns the keccak hash of the ABI-encoded StoredBlockInfo\n    function _hashStoredBlockInfo(StoredBlockInfo memory _storedBlockInfo) internal pure returns (bytes32) {\n        return keccak256(abi.encode(_storedBlockInfo));\n    }\n}"
    }
  ]
}